{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46268461-8eba-4885-b76c-e6b9f359d8cd",
   "metadata": {},
   "source": [
    "5단계 까지 도출한 사항을 정리하자면,\n",
    "\n",
    "Weight Capacity (kg)는 Price를 예측할 수 있는 Key feature 이다. Weight Capacity (kg)는 범주형 성격을 보이는데, \n",
    "\n",
    "이 배경에는 동일한 Weight Capacity (kg)에는 동일한 노이즈가 부여되었음이 짐작이 된다. \n",
    "\n",
    "이 점은 phase1~5 까지의 여러 실험을 통해 이로 인해 나타나는 결과를 통해 유력함을 확인했습니다. \n",
    "\n",
    "단계에서는 이 점을 이용한 Weight Capacity (kg)를  train에 등장하는 Weight Capacity (kg)와 5, 30을 제외한 변수는\n",
    "\n",
    "Weight Capacity (kg)로 Mean encoding을 입력으로 하는 모델을 이용하고, \n",
    "\n",
    "그렇지 않으면 Mean Encoding을 하지 않은 모델을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf32f8b4-d6ee-4d7e-902d-4cd6203b9bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:35:06.664344: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-10 23:35:06.908394: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-10 23:35:07.676875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.3 (main, May  1 2024, 17:33:23) [GCC 11.4.0]\n",
      "pandas 2.2.2\n",
      "polars 1.12.0\n",
      "matplotlib 3.8.4\n",
      "seaborn 0.13.2\n",
      "numpy 1.26.4\n",
      "scipy 1.13.0\n",
      "sklearn 1.4.2\n",
      "lightgbm 4.3.0\n",
      "xgboost 2.1.2\n",
      "catboost 1.2.5\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "import dproc, sgml, sgnn, sgpp, sgutil, custpp\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, pl, mpl, sns, np, scipy, sklearn, lgb, xgb, cb]:\n",
    "    try:\n",
    "        print(i.__name__, i.__version__)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc12dc7-ef25-4faa-8738-0b4d9a2df745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold, ShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88aefc96-6cd2-4ef1-a6ad-29bee24b6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = sgutil.SGCache('img', 'result')\n",
    "ss = ShuffleSplit(n_splits = 1, train_size = 0.8, random_state = 123)\n",
    "kf = KFold(5, random_state = 123, shuffle=True)\n",
    "\n",
    "files = {\n",
    "    'train': os.path.join('data', 'train.csv'),\n",
    "    'train_extra': os.path.join('data', 'training_extra.csv'),\n",
    "    'test': os.path.join('data', 'test.csv'),\n",
    "}\n",
    "\n",
    "t = sc.cache_result(\n",
    "    'pipeline_2',\n",
    "    lambda : make_pipeline(\n",
    "        sgpp.PolarsProcessor(), \n",
    "        sgpp.ExprProcessor({\n",
    "            'Compartments_c' : pl.col('Compartments').cast(pl.String).cast(pl.Categorical)\n",
    "        }),\n",
    "        sgpp.PandasCoverter(index_col = 'id'),\n",
    "        sgpp.ApplyWrapper(\n",
    "            sgpp.CatArrangerFreq(1, na_value = 'Unknown'),\n",
    "            ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "        ), \n",
    "        custpp.WeightCapacityProcessor()\n",
    "    ).fit(files['train']),\n",
    "    rerun = 1\n",
    ")\n",
    "df_train = pd.concat(\n",
    "    [t.transform(files['train']), t.transform(files['train_extra'])], axis = 0\n",
    ")\n",
    "df_test = t.transform(files['test'])\n",
    "\n",
    "target = 'Price'\n",
    "X_cat = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Compartments_c']\n",
    "X_num = ['Weight Capacity (kg)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ba906c-801c-423d-9858-ecffd7b8d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_splitter(validation_fraction):\n",
    "    return lambda x: train_test_split(x, test_size = validation_fraction)\n",
    "\n",
    "config = {\n",
    "    'predict_func': lambda m, df, X: pd.Series(m.predict(df[X]), index = df.index).clip(15, 150),\n",
    "    'score_func': lambda df, prds: root_mean_squared_error(df[target].sort_index(), prds.sort_index()),\n",
    "    'validation_splitter': get_validation_splitter,\n",
    "    'progress_callback': sgml.ProgressCallBack(), \n",
    "    'return_train_scores': True,\n",
    "    'y': target,\n",
    "}\n",
    "\n",
    "cb_adapter = sgml.CBAdapter(cb.CatBoostRegressor)\n",
    "lr_adapter = sgml.SklearnAdapter(LinearRegression)\n",
    "lgb_adapter = sgml.LGBMAdapter(lgb.LGBMRegressor)\n",
    "xgb_adapter = sgml.XGBAdapter(xgb.XGBRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99b5ddf-711e-4eea-aff7-9992924b1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(hparams, adapter, case = 0, sp = ss, **args):\n",
    "    results = list()\n",
    "    for train_idx, valid_idx in sp.split(df_train, df_train[target]):\n",
    "        df_cv_train, df_valid = df_train.iloc[train_idx], df_train.iloc[valid_idx]\n",
    "        bidx = df_valid['Weight Capacity (kg)'].isin(df_cv_train['Weight Capacity (kg)'].unique()) & df_valid['Weight Capacity (kg)'].notna() &\\\n",
    "                df_valid['Weight Capacity (kg)'].between(5, 30, inclusive = 'neither')\n",
    "        if case == 1:\n",
    "            bidx = ~bidx\n",
    "        df_valid = df_valid.loc[bidx]\n",
    "        reg = sgml.train(df_cv_train, hparams, config, adapter, **args)\n",
    "        prd = make_pipeline(reg[0]['preprocessor'], reg[0]['model']).predict(df_valid[reg[1]])\n",
    "        results.append(\n",
    "            (reg, root_mean_squared_error(df_valid[target], prd), pd.Series(prd, index = df_valid.index, name = Target))\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e6ce1d-17a7-4c56-8e1d-b14efdd5017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(metric  set  \n",
       " RMSE    learn    699\n",
       " dtype: int64,\n",
       " 38.637942532234035)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sc.cache_result(\n",
    "    'cv_cb1_0',\n",
    "    lambda : eval_model({\n",
    "        'model_params' : {'n_estimators': 700, 'max_depth': 7, 'learning_rate': 0.1},\n",
    "        'X_num': X_num, 'X_cat': X_cat, 'X_tgt': ['wc_i2'], 'tgt': {'cv': 24, 'smooth': 20, 'target_type': 'continuous', 'random_state': 123},\n",
    "        #'validation_fraction': 0.1\n",
    "    }, cb_adapter, case = 0, sp = kf, task_type = 'GPU')\n",
    ")\n",
    "sgml.cb_learning_result(results[0][0][0])['valid_result'].idxmin(), results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce784429-8609-49bc-b2b8-48f923d7bef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(metric  set  \n",
       " RMSE    learn    999\n",
       " dtype: int64,\n",
       " 39.22134932845147)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sc.cache_result(\n",
    "    'cv_cb1_1',\n",
    "    lambda :eval_model({\n",
    "        'model_params' : {'n_estimators': 1000, 'max_depth': 7, 'learning_rate': 0.1},\n",
    "        'X_num': X_num, 'X_cat': X_cat,\n",
    "    #    'validation_fraction': 0.1\n",
    "    }, cb_adapter, case = 1, sp = kf, task_type = 'GPU')\n",
    ")\n",
    "sgml.cb_learning_result(results[0][0][0])['valid_result'].idxmin(), results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6a4e2-6de8-4a56-8431-dec483c266a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
