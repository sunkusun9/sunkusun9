{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2e83d-0d6f-4efc-bed0-2cb3967d86e9",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    이미지를 불러옵니다.\n",
    "    Parameters:\n",
    "        filename: str\n",
    "            h5 파일에서 데이터를 불러옵니다.\n",
    "    Returns:\n",
    "        np.ndarray, pd.DataFrame, np.ndarray, \n",
    "        train 이미지, train spot 정보, test 이미지, test spot 정보\n",
    "    \"\"\"\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        # Train 이미지를 불러옵니다.\n",
    "        # 하나의 텐서로 만들기 위해 이미지의 크기를 2000x2000으로 균일하게 만듭니다.\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "        # Test 이미지를 불러옵니다.\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "    # EfficientNet의 형식으로 바꿉니다.\n",
    "    with tf.device('/CPU:0'):\n",
    "        images = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images))\n",
    "    df_spots = pd.concat(spots)\n",
    "    with tf.device('/CPU:0'):\n",
    "        images_test = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images_test))\n",
    "    df_spots_test = pd.concat(spots_test)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, df[targets])\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "augmentation_layers = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]\n",
    "\n",
    "target_proc = make_pipeline(FunctionTransformer(np.log, np.exp),  MinMaxScaler((-1, 1)))\n",
    "target_proc.fit(df_spots[targets])\n",
    "df_spots[targets] = target_proc.transform(df_spots[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22c6c30-1da4-4437-9ba1-e81bbe23a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22d774a-5ca2-4a50-bb36-c626fbbf4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08aa61c-806d-4c04-b228-132bd9491c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spots['slide'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dfe8a-7972-460e-b0fb-cab0b823ff1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "674c7d25-77b2-44c1-bf63-71e9de027b72",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c232f76-f043-4274-bde7-2e9743e39112",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_cv_train = create_tf_ds(\n",
    "    df_spots.loc[df_spots['slide'] != 5].pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "ds_valid = create_tf_ds(df_spots.loc[df_spots['slide'] == 5]).map(\n",
    "    lambda X, Y: (proc_images(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffea29a-6174-4f4d-b698-f48043b903ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 93ms/step - loss: 0.1780 - mean_squared_error: 0.1780 - val_loss: 0.1383 - val_mean_squared_error: 0.1383\n",
      "Epoch 2/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.1462 - mean_squared_error: 0.1462 - val_loss: 0.1276 - val_mean_squared_error: 0.1276\n",
      "Epoch 3/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.1336 - mean_squared_error: 0.1336 - val_loss: 0.1198 - val_mean_squared_error: 0.1198\n",
      "Epoch 4/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - loss: 0.1256 - mean_squared_error: 0.1256 - val_loss: 0.1167 - val_mean_squared_error: 0.1167\n",
      "Epoch 5/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.1205 - mean_squared_error: 0.1205 - val_loss: 0.1134 - val_mean_squared_error: 0.1134\n",
      "Epoch 6/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.1161 - mean_squared_error: 0.1161 - val_loss: 0.1113 - val_mean_squared_error: 0.1113\n",
      "Epoch 7/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.1124 - mean_squared_error: 0.1124 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 8/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1095 - mean_squared_error: 0.1095 - val_loss: 0.1067 - val_mean_squared_error: 0.1067\n",
      "Epoch 9/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.1079 - mean_squared_error: 0.1079 - val_loss: 0.1058 - val_mean_squared_error: 0.1058\n",
      "Epoch 10/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - loss: 0.1059 - mean_squared_error: 0.1059 - val_loss: 0.1070 - val_mean_squared_error: 0.1070\n",
      "Epoch 11/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.1043 - mean_squared_error: 0.1043 - val_loss: 0.1051 - val_mean_squared_error: 0.1051\n",
      "Epoch 12/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.1035 - mean_squared_error: 0.1035 - val_loss: 0.1039 - val_mean_squared_error: 0.1039\n",
      "Epoch 13/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1024 - mean_squared_error: 0.1024 - val_loss: 0.1034 - val_mean_squared_error: 0.1034\n",
      "Epoch 14/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1014 - mean_squared_error: 0.1014 - val_loss: 0.1025 - val_mean_squared_error: 0.1025\n",
      "Epoch 15/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.1013 - mean_squared_error: 0.1013 - val_loss: 0.1026 - val_mean_squared_error: 0.1026\n",
      "Epoch 16/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1009 - mean_squared_error: 0.1009 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 17/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - loss: 0.1000 - mean_squared_error: 0.1000 - val_loss: 0.1018 - val_mean_squared_error: 0.1018\n",
      "Epoch 18/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.1000 - mean_squared_error: 0.1000 - val_loss: 0.1019 - val_mean_squared_error: 0.1019\n",
      "Epoch 19/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.0995 - mean_squared_error: 0.0995 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 20/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0992 - mean_squared_error: 0.0992 - val_loss: 0.1013 - val_mean_squared_error: 0.1013\n",
      "Epoch 21/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0994 - mean_squared_error: 0.0994 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 22/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.0992 - mean_squared_error: 0.0992 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 23/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0990 - mean_squared_error: 0.0990 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 24/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - loss: 0.0989 - mean_squared_error: 0.0989 - val_loss: 0.1010 - val_mean_squared_error: 0.1010\n",
      "Epoch 25/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.0986 - mean_squared_error: 0.0986 - val_loss: 0.1010 - val_mean_squared_error: 0.1010\n",
      "Epoch 26/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0983 - mean_squared_error: 0.0983 - val_loss: 0.1010 - val_mean_squared_error: 0.1010\n",
      "Epoch 27/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - loss: 0.0980 - mean_squared_error: 0.0980 - val_loss: 0.1007 - val_mean_squared_error: 0.1007\n",
      "Epoch 28/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0984 - mean_squared_error: 0.0984 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
      "Epoch 29/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.0974 - mean_squared_error: 0.0974 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n",
      "Epoch 30/30\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - loss: 0.0976 - mean_squared_error: 0.0976 - val_loss: 0.1005 - val_mean_squared_error: 0.1005\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')(x)\n",
    "outputs = tf.keras.layers.Dense(len(targets))(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.MeanSquaredError()]\n",
    ")\n",
    "hist = m.fit(ds_cv_train, validation_data = ds_valid, epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407dfd-3912-44ff-bb8b-222943e7ef1c",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "과적합을 유의해야하는 데이터셋으로 판단되고 큰 도움은 되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "337e0bb0-6ba1-408f-bbc0-c45851d7dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"enet.trainable = True\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-6),  # Low learning rate\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "hist = m.fit(ds_cv_train, validation_data = ds_valid, epochs = 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab58473-e4a2-4138-9981-0ded6a2f548b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fe4a34-f38a-44f7-9802-a4e7d9186cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 179ms/step - loss: 0.1945 - mean_squared_error: 0.1945\n",
      "Epoch 2/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1452 - mean_squared_error: 0.1452\n",
      "Epoch 3/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.1300 - mean_squared_error: 0.1300\n",
      "Epoch 4/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.1221 - mean_squared_error: 0.1221\n",
      "Epoch 5/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 70ms/step - loss: 0.1170 - mean_squared_error: 0.1170\n",
      "Epoch 6/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.1131 - mean_squared_error: 0.1131\n",
      "Epoch 7/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.1099 - mean_squared_error: 0.1099\n",
      "Epoch 8/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.1072 - mean_squared_error: 0.1072\n",
      "Epoch 9/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.1050 - mean_squared_error: 0.1050\n",
      "Epoch 10/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.1033 - mean_squared_error: 0.1033\n",
      "Epoch 11/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.1020 - mean_squared_error: 0.1020\n",
      "Epoch 12/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.1007 - mean_squared_error: 0.1007\n",
      "Epoch 13/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - loss: 0.0996 - mean_squared_error: 0.0996\n",
      "Epoch 14/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 68ms/step - loss: 0.0989 - mean_squared_error: 0.0989\n",
      "Epoch 15/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.0978 - mean_squared_error: 0.0978\n",
      "Epoch 16/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - loss: 0.0977 - mean_squared_error: 0.0977\n",
      "Epoch 17/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0967 - mean_squared_error: 0.0967\n",
      "Epoch 18/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.0964 - mean_squared_error: 0.0964\n",
      "Epoch 19/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - loss: 0.0965 - mean_squared_error: 0.0965\n",
      "Epoch 20/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.0963 - mean_squared_error: 0.0963\n",
      "Epoch 21/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - loss: 0.0959 - mean_squared_error: 0.0959\n",
      "Epoch 22/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - loss: 0.0962 - mean_squared_error: 0.0962\n",
      "Epoch 23/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.0958 - mean_squared_error: 0.0958\n",
      "Epoch 24/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0954 - mean_squared_error: 0.0954\n",
      "Epoch 25/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - loss: 0.0957 - mean_squared_error: 0.0957\n",
      "Epoch 26/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 73ms/step - loss: 0.0951 - mean_squared_error: 0.0951\n",
      "Epoch 27/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0948 - mean_squared_error: 0.0948\n",
      "Epoch 28/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.0947 - mean_squared_error: 0.0947\n",
      "Epoch 29/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0947 - mean_squared_error: 0.0947\n",
      "Epoch 30/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.0946 - mean_squared_error: 0.0946\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_train = create_tf_ds(\n",
    "    df_spots.pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')(x)\n",
    "outputs = tf.keras.layers.Dense(len(targets))(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.MeanSquaredError()]\n",
    ")\n",
    "hist = m.fit(ds_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8872b7f4-5a81-4cbe-bf0e-860c1fecae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/eff_b0.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m, 'model/eff_b0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324394a4-4a9d-4ac1-a7ab-e923c2c3b5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/target_proc.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(target_proc, 'model/target_proc.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)\n",
    "\n",
    "df_submission = pd.DataFrame(\n",
    "    np.exp(\n",
    "        m.predict(\n",
    "            ds_test.map(lambda X: proc_images(X)).batch(32)\n",
    "        )\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>C31</th>\n",
       "      <th>C32</th>\n",
       "      <th>C33</th>\n",
       "      <th>C34</th>\n",
       "      <th>C35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.059851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128045</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.204422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.076468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.137513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.039391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.158754</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.120627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032568</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.114594</td>\n",
       "      <td>0.134391</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.124492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.054116</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.080666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>0.076367</td>\n",
       "      <td>0.124544</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>0.089570</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>0.134732</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.135976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.085672</td>\n",
       "      <td>0.118656</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.114055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>0.120247</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.106010</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.279060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.060093</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.097737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.087320</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043730</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.084443</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.087110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.151359</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.163655</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.044984</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.041145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.075038</td>\n",
       "      <td>0.084462</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.044275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        C1        C2        C3        C4        C5        C6  \\\n",
       "0        0  0.106880  0.117950  0.103375  0.005968  0.003798  0.024129   \n",
       "1        1  0.128045  0.116623  0.138590  0.010258  0.007435  0.050321   \n",
       "2        2  0.099630  0.098611  0.100010  0.008563  0.018887  0.026819   \n",
       "3        3  0.180319  0.137755  0.158754  0.006162  0.006356  0.041420   \n",
       "4        4  0.087845  0.145078  0.084427  0.001418  0.001762  0.010620   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2083  2083  0.076367  0.124544  0.080420  0.005161  0.014594  0.023217   \n",
       "2084  2084  0.109420  0.134732  0.117060  0.002985  0.003336  0.030402   \n",
       "2085  2085  0.149589  0.089491  0.120247  0.006303  0.009186  0.106010   \n",
       "2086  2086  0.088822  0.163909  0.087320  0.001273  0.002170  0.009971   \n",
       "2087  2087  0.151359  0.098457  0.163655  0.015520  0.044984  0.013516   \n",
       "\n",
       "            C7        C8        C9  ...       C26       C27       C28  \\\n",
       "0     0.035309  0.008406  0.098681  ...  0.013731  0.019819  0.012259   \n",
       "1     0.042165  0.009597  0.204422  ...  0.015731  0.056274  0.016234   \n",
       "2     0.027433  0.006014  0.137513  ...  0.006670  0.036991  0.006439   \n",
       "3     0.081333  0.030389  0.120627  ...  0.032568  0.036748  0.034174   \n",
       "4     0.054116  0.025442  0.053148  ...  0.036336  0.012387  0.023168   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2083  0.056135  0.016682  0.076528  ...  0.019992  0.027192  0.016148   \n",
       "2084  0.056009  0.022790  0.135976  ...  0.039139  0.036089  0.032287   \n",
       "2085  0.041300  0.011640  0.279060  ...  0.021469  0.122370  0.035616   \n",
       "2086  0.064393  0.025293  0.044465  ...  0.043730  0.010352  0.019291   \n",
       "2087  0.034210  0.005261  0.041145  ...  0.006100  0.015927  0.006985   \n",
       "\n",
       "           C29       C30       C31       C32       C33       C34       C35  \n",
       "0     0.018550  0.002482  0.061982  0.069548  0.009430  0.010013  0.059851  \n",
       "1     0.026071  0.001425  0.072266  0.080541  0.011042  0.010376  0.076468  \n",
       "2     0.011987  0.001200  0.062143  0.067901  0.003298  0.007506  0.039391  \n",
       "3     0.035257  0.004906  0.114594  0.134391  0.015988  0.024055  0.124492  \n",
       "4     0.025999  0.013443  0.077650  0.096791  0.019800  0.012882  0.080666  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2083  0.040179  0.002422  0.089227  0.089570  0.010097  0.009481  0.072841  \n",
       "2084  0.035312  0.006070  0.085672  0.118656  0.019103  0.013551  0.114055  \n",
       "2085  0.024045  0.000779  0.060093  0.092103  0.008761  0.014749  0.097737  \n",
       "2086  0.025303  0.020673  0.084443  0.089774  0.022668  0.014188  0.087110  \n",
       "2087  0.010253  0.001238  0.075038  0.084462  0.002773  0.008973  0.044275  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c4af3-6440-4902-9667-1083ee40ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
