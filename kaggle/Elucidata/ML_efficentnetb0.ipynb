{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:28:47.672098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743157727.683544   83934 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743157727.687073   83934 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743157727.696005   83934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743157727.696016   83934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743157727.696018   83934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743157727.696019   83934 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 10:28:47.698911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743157730.045914   83934 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "    \n",
    "\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "        \n",
    "    images = tf.constant(images)\n",
    "    df_spots = pd.concat(spots)\n",
    "    images_test = tf.constant(images_test)\n",
    "    df_spots_test = pd.concat(spots_test)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, np.log(df[targets]))\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22c6c30-1da4-4437-9ba1-e81bbe23a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ef10ed-70c9-4f7e-8dde-03749f320ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = create_tf_ds(df_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1adbee7a-7e8b-4e96-b001-fe187635cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22d774a-5ca2-4a50-bb36-c626fbbf4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61382a7-fa7d-48c7-bb34-8b5f7898d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dense(512, activation = 'relu', kernel_initializer = 'HeNormal')(x)\n",
    "outputs = tf.keras.layers.Dense(len(targets))(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0a7bd9-c105-45b8-a66e-5fb751b444b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = [tf.keras.metrics.MeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701d70c7-b887-4563-a377-87cfe14d1d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 165ms/step - loss: 2.2822 - mean_squared_error: 2.2822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa4c4227020>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(ds_train.shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X), Y)\n",
    ").batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "df_submission = pd.DataFrame(\n",
    "    np.exp(\n",
    "        m.predict(\n",
    "            ds_test.map(lambda X: proc_images(X)).batch(64)\n",
    "        )\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>C31</th>\n",
       "      <th>C32</th>\n",
       "      <th>C33</th>\n",
       "      <th>C34</th>\n",
       "      <th>C35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.059851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128045</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.204422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.076468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.137513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.039391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.158754</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.120627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032568</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.114594</td>\n",
       "      <td>0.134391</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.124492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.054116</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.080666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>0.076367</td>\n",
       "      <td>0.124544</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>0.089570</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>0.134732</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.135976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.085672</td>\n",
       "      <td>0.118656</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.114055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>0.120247</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.106010</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.279060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.060093</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.097737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.087320</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043730</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.084443</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.087110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.151359</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.163655</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.044984</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.041145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.075038</td>\n",
       "      <td>0.084462</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.044275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        C1        C2        C3        C4        C5        C6  \\\n",
       "0        0  0.106880  0.117950  0.103375  0.005968  0.003798  0.024129   \n",
       "1        1  0.128045  0.116623  0.138590  0.010258  0.007435  0.050321   \n",
       "2        2  0.099630  0.098611  0.100010  0.008563  0.018887  0.026819   \n",
       "3        3  0.180319  0.137755  0.158754  0.006162  0.006356  0.041420   \n",
       "4        4  0.087845  0.145078  0.084427  0.001418  0.001762  0.010620   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2083  2083  0.076367  0.124544  0.080420  0.005161  0.014594  0.023217   \n",
       "2084  2084  0.109420  0.134732  0.117060  0.002985  0.003336  0.030402   \n",
       "2085  2085  0.149589  0.089491  0.120247  0.006303  0.009186  0.106010   \n",
       "2086  2086  0.088822  0.163909  0.087320  0.001273  0.002170  0.009971   \n",
       "2087  2087  0.151359  0.098457  0.163655  0.015520  0.044984  0.013516   \n",
       "\n",
       "            C7        C8        C9  ...       C26       C27       C28  \\\n",
       "0     0.035309  0.008406  0.098681  ...  0.013731  0.019819  0.012259   \n",
       "1     0.042165  0.009597  0.204422  ...  0.015731  0.056274  0.016234   \n",
       "2     0.027433  0.006014  0.137513  ...  0.006670  0.036991  0.006439   \n",
       "3     0.081333  0.030389  0.120627  ...  0.032568  0.036748  0.034174   \n",
       "4     0.054116  0.025442  0.053148  ...  0.036336  0.012387  0.023168   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2083  0.056135  0.016682  0.076528  ...  0.019992  0.027192  0.016148   \n",
       "2084  0.056009  0.022790  0.135976  ...  0.039139  0.036089  0.032287   \n",
       "2085  0.041300  0.011640  0.279060  ...  0.021469  0.122370  0.035616   \n",
       "2086  0.064393  0.025293  0.044465  ...  0.043730  0.010352  0.019291   \n",
       "2087  0.034210  0.005261  0.041145  ...  0.006100  0.015927  0.006985   \n",
       "\n",
       "           C29       C30       C31       C32       C33       C34       C35  \n",
       "0     0.018550  0.002482  0.061982  0.069548  0.009430  0.010013  0.059851  \n",
       "1     0.026071  0.001425  0.072266  0.080541  0.011042  0.010376  0.076468  \n",
       "2     0.011987  0.001200  0.062143  0.067901  0.003298  0.007506  0.039391  \n",
       "3     0.035257  0.004906  0.114594  0.134391  0.015988  0.024055  0.124492  \n",
       "4     0.025999  0.013443  0.077650  0.096791  0.019800  0.012882  0.080666  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2083  0.040179  0.002422  0.089227  0.089570  0.010097  0.009481  0.072841  \n",
       "2084  0.035312  0.006070  0.085672  0.118656  0.019103  0.013551  0.114055  \n",
       "2085  0.024045  0.000779  0.060093  0.092103  0.008761  0.014749  0.097737  \n",
       "2086  0.025303  0.020673  0.084443  0.089774  0.022668  0.014188  0.087110  \n",
       "2087  0.010253  0.001238  0.075038  0.084462  0.002773  0.008973  0.044275  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c4af3-6440-4902-9667-1083ee40ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
