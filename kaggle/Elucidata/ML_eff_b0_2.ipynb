{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2e83d-0d6f-4efc-bed0-2cb3967d86e9",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    이미지를 불러옵니다.\n",
    "    Parameters:\n",
    "        filename: str\n",
    "            h5 파일에서 데이터를 불러옵니다.\n",
    "    Returns:\n",
    "        np.ndarray, pd.DataFrame, np.ndarray, \n",
    "        train 이미지, train spot 정보, test 이미지, test spot 정보\n",
    "    \"\"\"\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        # Train 이미지를 불러옵니다.\n",
    "        # 하나의 텐서로 만들기 위해 이미지의 크기를 2000x2000으로 균일하게 만듭니다.\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "        # Test 이미지를 불러옵니다.\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "    # EfficientNet의 형식으로 바꿉니다.\n",
    "    with tf.device('/CPU:0'):\n",
    "        images = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images))\n",
    "    df_spots = pd.concat(spots)\n",
    "    with tf.device('/CPU:0'):\n",
    "        images_test = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images_test))\n",
    "    df_spots_test = pd.concat(spots_test)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, df[targets])\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X, images):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "augmentation_layers = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]\n",
    "\n",
    "target_proc = make_pipeline(FunctionTransformer(np.log, np.exp),  StandardScaler())\n",
    "target_proc.fit(df_spots[targets])\n",
    "df_spots[targets] = target_proc.transform(df_spots[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22c6c30-1da4-4437-9ba1-e81bbe23a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08aa61c-806d-4c04-b228-132bd9491c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spots['slide'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class TqdmEpochProgress(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.progress_bar = tqdm(total=self.epochs, desc=\"Epochs\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log_str = f\"loss: {logs.get('loss'):.4f}\"\n",
    "        if 'val_loss' in logs:\n",
    "            log_str += f\", val_loss: {logs.get('val_loss'):.4f}\"\n",
    "        self.progress_bar.set_postfix_str(log_str)\n",
    "        self.progress_bar.update(1)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d25-77b2-44c1-bf63-71e9de027b72",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ffea29a-6174-4f4d-b698-f48043b903ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_cv_train = create_tf_ds(\n",
    "    df_spots.loc[df_spots['slide'] != 5].pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "ds_valid = create_tf_ds(df_spots.loc[df_spots['slide'] == 5]).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b0361f2-c92f-4e18-b538-62b4ea3ff213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 76ms/step - loss: 1.1092 - mean_squared_error: 1.1092\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 342ms/step\n",
      "0.518999081294782 0.33009170559704354\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 1.0521 - mean_squared_error: 1.0521\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5207991733278677 0.3290757018812078\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 1.0219 - mean_squared_error: 1.0219\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5601591856254697 0.32236360870606423\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 84ms/step - loss: 0.9986 - mean_squared_error: 0.9986\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5699605451936872 0.3200590939559671\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - loss: 0.9810 - mean_squared_error: 0.9810\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5653822504611601 0.3187721206633479\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.9682 - mean_squared_error: 0.9682\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5683396529343445 0.3181607028137847\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.9548 - mean_squared_error: 0.9548\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5688665710186513 0.31779460321521463\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.9442 - mean_squared_error: 0.9442\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5701433012229282 0.3174564065400708\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.9335 - mean_squared_error: 0.9335\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5709153173464508 0.31735745191692627\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.9246 - mean_squared_error: 0.9246\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5715336134453781 0.31726831468443295\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.9193 - mean_squared_error: 0.9193\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5711450433832069 0.31700278291911904\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - loss: 0.9118 - mean_squared_error: 0.9118\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5713875794220127 0.3168323360892438\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.9084 - mean_squared_error: 0.9084\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5718205574912892 0.31682022073792354\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - loss: 0.9026 - mean_squared_error: 0.9026\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5718649654983945 0.31669044864111867\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.9002 - mean_squared_error: 0.9002\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.572514005602241 0.31669458934260825\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.8973 - mean_squared_error: 0.8973\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5719623215139714 0.31661018509885314\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 85ms/step - loss: 0.8938 - mean_squared_error: 0.8938\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5715045774407325 0.3164159077241221\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.8941 - mean_squared_error: 0.8941\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5715891234542598 0.31639253918464405\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - loss: 0.8926 - mean_squared_error: 0.8926\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.571813725490196 0.31633498297141266\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.8903 - mean_squared_error: 0.8903\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5718837535014006 0.3164302528270953\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 84ms/step - loss: 0.8900 - mean_squared_error: 0.8900\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5720443055270888 0.31623860175582197\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 0.8887 - mean_squared_error: 0.8887\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5718717974994877 0.31626297849861734\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.8871 - mean_squared_error: 0.8871\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5715609414497506 0.316206164525591\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.8857 - mean_squared_error: 0.8857\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5723748035799685 0.31614222431039113\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - loss: 0.8839 - mean_squared_error: 0.8839\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5721365375418461 0.31602303199235887\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.8855 - mean_squared_error: 0.8855\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5722663455626154 0.316006597412141\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 77ms/step - loss: 0.8836 - mean_squared_error: 0.8836\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5721843615494979 0.3160459644901522\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 84ms/step - loss: 0.8828 - mean_squared_error: 0.8828\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5722356015576963 0.31603270687309143\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.8808 - mean_squared_error: 0.8808\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5720460135273623 0.31595715321365364\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - loss: 0.8804 - mean_squared_error: 0.8804\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5722501195600191 0.31589615876197663\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.MeanSquaredError()]\n",
    ")\n",
    "df_true = pd.DataFrame(\n",
    "    target_proc.inverse_transform(\n",
    "        df_spots.loc[df_spots['slide'] == 5, targets]\n",
    "    ), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    ")\n",
    "for i in range(30):\n",
    "    hist = m.fit(ds_cv_train, epochs = 1)\n",
    "    df_prd = pd.DataFrame(\n",
    "        target_proc.inverse_transform(m.predict(ds_valid)), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407dfd-3912-44ff-bb8b-222943e7ef1c",
   "metadata": {},
   "source": [
    "# Fine Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "337e0bb0-6ba1-408f-bbc0-c45851d7dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 78ms/step - loss: 0.8075 - mean_squared_error: 0.8075\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 301ms/step\n",
      "0.5723167315706771 0.310563293689337\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.8002 - mean_squared_error: 0.8002\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5730656896905104 0.31008050635853646\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 84ms/step - loss: 0.7902 - mean_squared_error: 0.7902\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5714456514313042 0.3101638124620468\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.7807 - mean_squared_error: 0.7807\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5698879551820728 0.3100369421991883\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.7722 - mean_squared_error: 0.7722\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5694387511102001 0.30977486910956953\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.7638 - mean_squared_error: 0.7638\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5684754389560703 0.31028821340196205\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - loss: 0.7546 - mean_squared_error: 0.7546\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5679638928742229 0.310410805790021\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.7448 - mean_squared_error: 0.7448\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "0.5676701168272188 0.31077368097574987\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - loss: 0.7357 - mean_squared_error: 0.7357\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5659834665573547 0.31131320309757377\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - loss: 0.7279 - mean_squared_error: 0.7279\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "0.5651362984218078 0.312146447830061\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-6),  # Low learning rate\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "for i in range(10):\n",
    "    hist = m.fit(ds_cv_train, epochs=1)\n",
    "    df_prd = pd.DataFrame(\n",
    "        target_proc.inverse_transform(m.predict(ds_valid)), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab58473-e4a2-4138-9981-0ded6a2f548b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c78e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 186ms/step - loss: 1.1314 - mean_squared_error: 1.1314\n",
      "Epoch 2/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 1.0609 - mean_squared_error: 1.0609\n",
      "Epoch 3/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 1.0237 - mean_squared_error: 1.0237\n",
      "Epoch 4/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 1.0044 - mean_squared_error: 1.0044\n",
      "Epoch 5/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 85ms/step - loss: 0.9836 - mean_squared_error: 0.9836\n",
      "Epoch 6/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9676 - mean_squared_error: 0.9676\n",
      "Epoch 7/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9550 - mean_squared_error: 0.9550\n",
      "Epoch 8/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9435 - mean_squared_error: 0.9435\n",
      "Epoch 9/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.9320 - mean_squared_error: 0.9320\n",
      "Epoch 10/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9239 - mean_squared_error: 0.9239\n",
      "Epoch 11/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.9171 - mean_squared_error: 0.9171\n",
      "Epoch 12/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.9108 - mean_squared_error: 0.9108\n",
      "Epoch 13/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 76ms/step - loss: 0.9043 - mean_squared_error: 0.9043\n",
      "Epoch 14/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.9005 - mean_squared_error: 0.9005\n",
      "Epoch 15/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - loss: 0.8973 - mean_squared_error: 0.8973\n",
      "Epoch 16/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8936 - mean_squared_error: 0.8936\n",
      "Epoch 17/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8934 - mean_squared_error: 0.8934\n",
      "Epoch 18/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - loss: 0.8897 - mean_squared_error: 0.8897\n",
      "Epoch 19/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.8864 - mean_squared_error: 0.8864\n",
      "Epoch 20/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 0.8867 - mean_squared_error: 0.8867\n",
      "Epoch 21/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8850 - mean_squared_error: 0.8850\n",
      "Epoch 22/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - loss: 0.8846 - mean_squared_error: 0.8846\n",
      "Epoch 23/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8825 - mean_squared_error: 0.8825\n",
      "Epoch 24/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8818 - mean_squared_error: 0.8818\n",
      "Epoch 25/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8805 - mean_squared_error: 0.8805\n",
      "Epoch 26/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - loss: 0.8810 - mean_squared_error: 0.8810\n",
      "Epoch 27/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - loss: 0.8793 - mean_squared_error: 0.8793\n",
      "Epoch 28/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 0.8771 - mean_squared_error: 0.8771\n",
      "Epoch 29/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - loss: 0.8765 - mean_squared_error: 0.8765\n",
      "Epoch 30/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 76ms/step - loss: 0.8734 - mean_squared_error: 0.8734\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_train = create_tf_ds(\n",
    "    df_spots.pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.MeanSquaredError()]\n",
    ")\n",
    "hist = m.fit(ds_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543df0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    ")\n",
    "hist = m.fit(ds_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872b7f4-5a81-4cbe-bf0e-860c1fecae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(m.get_weights, 'model/eff_b0_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324394a4-4a9d-4ac1-a7ab-e923c2c3b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(target_proc, 'model/target_proc_2.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 124ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)\n",
    "\n",
    "df_submission = pd.DataFrame(\n",
    "    target_proc.inverse_transform(\n",
    "        m.predict(\n",
    "            ds_test.map(lambda X: proc_images(X, images_test)).batch(32)\n",
    "        )\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>C31</th>\n",
       "      <th>C32</th>\n",
       "      <th>C33</th>\n",
       "      <th>C34</th>\n",
       "      <th>C35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.077941</td>\n",
       "      <td>0.043652</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.098215</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003245</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.034370</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031405</td>\n",
       "      <td>0.039082</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.089328</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.031395</td>\n",
       "      <td>0.042351</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.023202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.073687</td>\n",
       "      <td>0.042339</td>\n",
       "      <td>0.057946</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.038751</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.016234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>0.313371</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.056375</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.047874</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.024612</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>0.049777</td>\n",
       "      <td>0.055029</td>\n",
       "      <td>0.062455</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.292763</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.026539</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.038822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>0.088948</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.371941</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.045683</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.056270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.047275</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.019584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>0.062852</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.115488</td>\n",
       "      <td>0.027797</td>\n",
       "      <td>0.073778</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.038626</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.058467</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>0.144921</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.017023</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.033640</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.067703</td>\n",
       "      <td>0.045217</td>\n",
       "      <td>0.132235</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.013317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        C1        C2        C3        C4        C5        C6  \\\n",
       "0        0  0.077941  0.043652  0.175470  0.011950  0.098215  0.003235   \n",
       "1        1  0.031405  0.039082  0.051170  0.006747  0.089328  0.002896   \n",
       "2        2  0.073687  0.042339  0.057946  0.003385  0.036626  0.001122   \n",
       "3        3  0.080863  0.043887  0.313371  0.016495  0.083784  0.003541   \n",
       "4        4  0.019779  0.047874  0.048455  0.007821  0.024612  0.001668   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2083  2083  0.049777  0.055029  0.062455  0.016545  0.292763  0.002689   \n",
       "2084  2084  0.035788  0.043603  0.088948  0.006203  0.371941  0.006795   \n",
       "2085  2085  0.062852  0.045850  0.115488  0.027797  0.073778  0.001217   \n",
       "2086  2086  0.016944  0.058467  0.063099  0.077487  0.144921  0.001477   \n",
       "2087  2087  0.067703  0.045217  0.132235  0.003996  0.043471  0.001366   \n",
       "\n",
       "            C7        C8        C9  ...       C26       C27       C28  \\\n",
       "0     0.012892  0.001753  0.003514  ...  0.003245  0.001521  0.000470   \n",
       "1     0.013572  0.005587  0.002254  ...  0.002828  0.000331  0.000757   \n",
       "2     0.014627  0.003375  0.003865  ...  0.002439  0.000503  0.000630   \n",
       "3     0.015294  0.001456  0.001234  ...  0.003949  0.000897  0.000696   \n",
       "4     0.003994  0.009856  0.000440  ...  0.003381  0.000609  0.000508   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2083  0.019779  0.001736  0.003108  ...  0.002948  0.004000  0.000985   \n",
       "2084  0.045683  0.000713  0.056270  ...  0.002693  0.005886  0.001566   \n",
       "2085  0.021061  0.002774  0.002420  ...  0.000932  0.000643  0.000667   \n",
       "2086  0.017023  0.004665  0.003143  ...  0.001426  0.000226  0.000780   \n",
       "2087  0.013778  0.007189  0.001468  ...  0.002191  0.000442  0.000355   \n",
       "\n",
       "           C29       C30       C31       C32       C33       C34       C35  \n",
       "0     0.000453  0.000523  0.034370  0.043636  0.000712  0.001227  0.018761  \n",
       "1     0.000414  0.000312  0.031395  0.042351  0.003108  0.000844  0.023202  \n",
       "2     0.000439  0.000582  0.038751  0.035186  0.000895  0.002870  0.016234  \n",
       "3     0.001236  0.000171  0.037267  0.056375  0.000779  0.002152  0.011728  \n",
       "4     0.000324  0.001303  0.026807  0.032900  0.001654  0.000868  0.016599  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2083  0.001082  0.000443  0.026539  0.054108  0.001340  0.000897  0.038822  \n",
       "2084  0.002723  0.000165  0.047275  0.072403  0.000397  0.002130  0.019584  \n",
       "2085  0.001292  0.000235  0.038626  0.017400  0.001952  0.001073  0.014109  \n",
       "2086  0.001270  0.000599  0.033640  0.044233  0.001922  0.000357  0.018170  \n",
       "2087  0.000238  0.003596  0.028340  0.017242  0.001507  0.003057  0.013317  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0618d052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03886d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
