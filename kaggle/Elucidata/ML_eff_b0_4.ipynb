{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 10:10:04.084061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743761404.095934  101032 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743761404.099584  101032 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743761404.108884  101032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743761404.108897  101032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743761404.108898  101032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743761404.108900  101032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2e83d-0d6f-4efc-bed0-2cb3967d86e9",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743761406.345391  101032 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    이미지를 불러옵니다.\n",
    "    Parameters:\n",
    "        filename: str\n",
    "            h5 파일에서 데이터를 불러옵니다.\n",
    "    Returns:\n",
    "        np.ndarray, pd.DataFrame, np.ndarray, \n",
    "        train 이미지, train spot 정보, test 이미지, test spot 정보\n",
    "    \"\"\"\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        # Train 이미지를 불러옵니다.\n",
    "        # 하나의 텐서로 만들기 위해 이미지의 크기를 2000x2000으로 균일하게 만듭니다.\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "        # Test 이미지를 불러옵니다.\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "    # EfficientNet의 형식으로 바꿉니다.\n",
    "    with tf.device('/CPU:0'):\n",
    "        images = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images))\n",
    "    df_spots = pd.concat(spots).reset_index(drop = True)\n",
    "    with tf.device('/CPU:0'):\n",
    "        images_test = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images_test))\n",
    "    df_spots_test = pd.concat(spots_test).reset_index(drop = True)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, df[targets])\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X, images):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "augmentation_layers = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(1.0),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1)\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]\n",
    "\n",
    "target_proc = make_pipeline(FunctionTransformer(np.log, np.exp),  StandardScaler())\n",
    "target_proc.fit(df_spots[targets])\n",
    "df_spots[targets] = target_proc.transform(df_spots[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08aa61c-806d-4c04-b228-132bd9491c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)\n",
    "\n",
    "df_spots['slide'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca898ab-8c12-468e-8853-8ab2b9bdcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseHingeLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"pairwise_hinge_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return tf.reduce_mean(\n",
    "            tf.maximum(\n",
    "                0.0, 1.0 - (tf.expand_dims(y_pred, axis=-1) - tf.expand_dims(y_pred, axis=-2))\n",
    "            ) * tf.cast(tf.expand_dims(y_true, axis=-1) > tf.expand_dims(y_true, axis=-2), dtype = tf.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "def create_model():\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    enet = tf.keras.applications.EfficientNetB0(\n",
    "        include_top = False, \n",
    "        weights = 'imagenet',\n",
    "        input_shape = input_shape,\n",
    "        pooling = 'avg'\n",
    "    )\n",
    "    inputs = tf.keras.Input(shape = input_shape)\n",
    "    x = enet(inputs, training = False)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    d1 = tf.keras.layers.Dense(256, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "    x = d1(x)\n",
    "    d2 = tf.keras.layers.Dense(len(targets))\n",
    "    outputs = d2(x)\n",
    "    m = tf.keras.models.Model(inputs, outputs)\n",
    "    return m, (enet, d1, d2)\n",
    "\n",
    "def reconstruct_model(layers):\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    inputs = tf.keras.Input(shape = input_shape)\n",
    "    x = layers[0](inputs, training = True)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = layers[1](x)\n",
    "    outputs = layers[2](x)\n",
    "    m = tf.keras.models.Model(inputs, outputs)\n",
    "    return m\n",
    "\n",
    "def train_model(\n",
    "        m, train_idx, valid_idx, learning_rate, \n",
    "        target_proc = FunctionTransformer(lambda x: x, lambda x: x), \n",
    "        batch_size = 32, epochs = 20, step = ''\n",
    "    ):\n",
    "    tf.keras.backend.clear_session()\n",
    "    ds = create_tf_ds(\n",
    "        df_spots.iloc[train_idx].pipe(\n",
    "            lambda x: pd.concat([\n",
    "                x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "            ])\n",
    "        )\n",
    "    )\n",
    "    ds_cv_train = ds.shuffle(5000).map(\n",
    "        lambda X, Y: (proc_images(X, images), Y)\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "    \"\"\"\n",
    "    .map(\n",
    "        lambda X, Y: (data_augmentation(X), Y)\n",
    "    )\n",
    "    \"\"\"\n",
    "    ds_cv_prd = ds.map(\n",
    "        lambda X, Y: (proc_images(X, images), Y)\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    \n",
    "    if valid_idx is not None:\n",
    "        ds_valid = create_tf_ds(df_spots.iloc[valid_idx]).map(\n",
    "            lambda X, Y: (proc_images(X, images), Y)\n",
    "        ).batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    else:\n",
    "        ds_valid = None\n",
    "    \"\"\"\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=5000,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \"\"\"\n",
    "    lr_schedule = learning_rate\n",
    "    m.compile(\n",
    "        loss = PairwiseHingeLoss(),\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "    )\n",
    "\n",
    "    df_true_train = df_spots.iloc[train_idx][targets].pipe(\n",
    "        lambda x: pd.DataFrame(\n",
    "            target_proc.inverse_transform(x), index = x.index, columns = targets\n",
    "        )\n",
    "    )\n",
    "    if valid_idx is not None:\n",
    "        df_true = df_spots.iloc[valid_idx][targets].pipe(\n",
    "            lambda x: pd.DataFrame(\n",
    "                target_proc.inverse_transform(x), index = x.index, columns = targets\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df_true = None\n",
    "    progress_bar = tqdm(total = epochs, desc=step)\n",
    "    scores_train, scores_valid = list(), list()\n",
    "    df_prd = None\n",
    "    for i in range(epochs):\n",
    "        hist = m.fit(ds_cv_train, epochs = 1, verbose = 0)\n",
    "        df_prd = pd.DataFrame(\n",
    "            target_proc.inverse_transform(m.predict(ds_cv_prd, verbose = 0))[:len(df_true_train)], \n",
    "            index = df_true_train.index, columns = targets\n",
    "        )\n",
    "        scores_train.append(\n",
    "            df_true_train.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean()\n",
    "        )\n",
    "        metric = \"train coef: {:.4f}\".format(scores_train[-1])\n",
    "        if valid_idx is not None:\n",
    "            df_prd = pd.DataFrame(\n",
    "                target_proc.inverse_transform(m.predict(ds_valid, verbose = 0)), \n",
    "                index = df_true.index, columns = targets\n",
    "            )\n",
    "            scores_valid.append(\n",
    "                df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean()\n",
    "            )\n",
    "            metric = metric + \", valid coef: {:.4f}\".format(scores_valid[-1])\n",
    "        progress_bar.set_postfix_str(metric)\n",
    "        progress_bar.update(1)\n",
    "    progress_bar.close()\n",
    "    tf.keras.backend.clear_session()\n",
    "    return scores, df_prd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea7d3c5-0094-4793-89ca-19bfd7e8d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5] [1]\n",
      "[1 2 3 4 5] [0]\n",
      "[0 1 2 3 5] [4]\n",
      "[0 1 2 4 5] [3]\n",
      "[0 1 3 4 5] [2]\n",
      "[0 1 2 3 4] [5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(n_splits = 6)\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(df_spots[['x', 'y']], df_spots[targets], groups = df_spots['slide'])\n",
    "):\n",
    "    print(df_spots.iloc[train_idx]['slide'].unique(), df_spots.iloc[valid_idx]['slide'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d25-77b2-44c1-bf63-71e9de027b72",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffea29a-6174-4f4d-b698-f48043b903ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()\n",
    "oofs = list()\n",
    "for i, (train_idx, valid_idx) in enumerate(\n",
    "    gkf.split(df_spots[['x', 'y']], df_spots[targets], groups = df_spots['slide'])\n",
    "):\n",
    "    m, layers = create_model()\n",
    "    score_1, df_prd = train_model(\n",
    "        m, train_idx, valid_idx, learning_rate = 1e-5, \n",
    "        batch_size = 32, epochs = 30, step = 'train {}'.format(i + 1)\n",
    "    )\n",
    "    \"\"\"\n",
    "    m = reconstruct_model(layers)\n",
    "    score_2, df_prd = train_model(\n",
    "        m, train_idx, valid_idx, learning_rate = 1e-6, \n",
    "        target_proc = target_proc, batch_size = 32, epochs = 10, step = 'fine tuning {}'.format(i + 1)\n",
    "    )\n",
    "    \"\"\"\n",
    "    scores.append(score_1)\n",
    "    oofs.append(df_prd)\n",
    "df_oof = pd.concat(oofs, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407dfd-3912-44ff-bb8b-222943e7ef1c",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "과적합을 유의해야하는 데이터셋으로 판단되고 큰 도움은 되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337e0bb0-6ba1-408f-bbc0-c45851d7dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 86ms/step - loss: 11995.6201 - pairwise_hinge_loss: 11995.6201\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step\n",
      "0.6002963380474141 0.8212345117065115\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11908.0615 - pairwise_hinge_loss: 11908.0615\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5968094554895129 0.7898164633285091\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11844.4688 - pairwise_hinge_loss: 11844.4688\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.601015406162465 0.8295621284427014\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11767.3506 - pairwise_hinge_loss: 11767.3506\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5994918699186993 0.8192455664835954\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11700.7139 - pairwise_hinge_loss: 11700.7139\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.603902780624445 0.8455492408696743\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11635.4600 - pairwise_hinge_loss: 11635.4600\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6058037849286055 0.8477143492033883\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11566.9990 - pairwise_hinge_loss: 11566.9990\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6028720024595204 0.8080375532812616\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11490.7559 - pairwise_hinge_loss: 11490.7559\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6060497369679579 0.8199202316543234\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11451.1230 - pairwise_hinge_loss: 11451.1230\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6042161986745919 0.8236801264047149\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11371.4131 - pairwise_hinge_loss: 11371.4131\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6107185557149689 0.8572205151066188\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=PairwiseHingeLoss(),\n",
    "    metrics=[PairwiseHingeLoss()],\n",
    ")\n",
    "for i in range(10):\n",
    "    hist = m.fit(ds_cv_train, epochs=1)\n",
    "    df_prd =  pd.DataFrame(\n",
    "       m.predict(ds_valid), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab58473-e4a2-4138-9981-0ded6a2f548b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71fe4a34-f38a-44f7-9802-a4e7d9186cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - loss: 17552.2695 - pairwise_hinge_loss: 17552.2695\n",
      "Epoch 2/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 16380.9219 - pairwise_hinge_loss: 16380.9219\n",
      "Epoch 3/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 15411.1494 - pairwise_hinge_loss: 15411.1494\n",
      "Epoch 4/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 14655.4277 - pairwise_hinge_loss: 14655.4277\n",
      "Epoch 5/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 14048.9863 - pairwise_hinge_loss: 14048.9863\n",
      "Epoch 6/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 13615.4727 - pairwise_hinge_loss: 13615.4727\n",
      "Epoch 7/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 13281.3789 - pairwise_hinge_loss: 13281.3789\n",
      "Epoch 8/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 12971.7100 - pairwise_hinge_loss: 12971.7100\n",
      "Epoch 9/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 12757.5244 - pairwise_hinge_loss: 12757.5244\n",
      "Epoch 10/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 78ms/step - loss: 12574.1973 - pairwise_hinge_loss: 12574.1973\n",
      "Epoch 11/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 12417.5566 - pairwise_hinge_loss: 12417.5566\n",
      "Epoch 12/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 12279.2227 - pairwise_hinge_loss: 12279.2227\n",
      "Epoch 13/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 12183.2998 - pairwise_hinge_loss: 12183.2998\n",
      "Epoch 14/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 12095.2393 - pairwise_hinge_loss: 12095.2393\n",
      "Epoch 15/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 12008.7793 - pairwise_hinge_loss: 12008.7793\n",
      "Epoch 16/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11966.9961 - pairwise_hinge_loss: 11966.9961\n",
      "Epoch 17/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - loss: 11925.9688 - pairwise_hinge_loss: 11925.9688\n",
      "Epoch 18/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11877.3535 - pairwise_hinge_loss: 11877.3535\n",
      "Epoch 19/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11868.4531 - pairwise_hinge_loss: 11868.4531\n",
      "Epoch 20/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11833.6436 - pairwise_hinge_loss: 11833.6436\n",
      "Epoch 21/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11797.8916 - pairwise_hinge_loss: 11797.8916\n",
      "Epoch 22/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11774.0098 - pairwise_hinge_loss: 11774.0098\n",
      "Epoch 23/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11755.4043 - pairwise_hinge_loss: 11755.4043\n",
      "Epoch 24/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - loss: 11732.1855 - pairwise_hinge_loss: 11732.1855\n",
      "Epoch 25/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - loss: 11720.7666 - pairwise_hinge_loss: 11720.7666\n",
      "Epoch 26/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11692.2979 - pairwise_hinge_loss: 11692.2979\n",
      "Epoch 27/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11674.4922 - pairwise_hinge_loss: 11674.4922\n",
      "Epoch 28/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - loss: 11647.8965 - pairwise_hinge_loss: 11647.8965\n",
      "Epoch 29/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11603.8770 - pairwise_hinge_loss: 11603.8770\n",
      "Epoch 30/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11603.0977 - pairwise_hinge_loss: 11603.0977\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_train = create_tf_ds(\n",
    "    df_spots.pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = PairwiseHingeLoss(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [PairwiseHingeLoss()]\n",
    ")\n",
    "hist = m.fit(ds_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68bab663-0dce-437c-97f1-58c476965cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 78ms/step - loss: 11561.5879 - pairwise_hinge_loss: 11561.5879\n",
      "Epoch 2/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11485.3896 - pairwise_hinge_loss: 11485.3896\n",
      "Epoch 3/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11412.0186 - pairwise_hinge_loss: 11412.0186\n",
      "Epoch 4/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 89ms/step - loss: 11356.1943 - pairwise_hinge_loss: 11356.1943\n",
      "Epoch 5/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11279.6406 - pairwise_hinge_loss: 11279.6406\n",
      "Epoch 6/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 97ms/step - loss: 11218.8232 - pairwise_hinge_loss: 11218.8232\n",
      "Epoch 7/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 58ms/step - loss: 11159.9199 - pairwise_hinge_loss: 11159.9199\n",
      "Epoch 8/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - loss: 11097.2285 - pairwise_hinge_loss: 11097.2285\n",
      "Epoch 9/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 11019.9414 - pairwise_hinge_loss: 11019.9414\n",
      "Epoch 10/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - loss: 10973.0107 - pairwise_hinge_loss: 10973.0107\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=PairwiseHingeLoss(),\n",
    "    metrics=[PairwiseHingeLoss()],\n",
    ")\n",
    "hist = m.fit(ds_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8872b7f4-5a81-4cbe-bf0e-860c1fecae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/eff_b0_4.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m.get_weights(), 'model/eff_b0_4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 138ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)\n",
    "\n",
    "df_submission = pd.DataFrame(\n",
    "    m.predict(\n",
    "        ds_test.map(lambda X: proc_images(X, images_test)).batch(32)\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c4af3-6440-4902-9667-1083ee40ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
