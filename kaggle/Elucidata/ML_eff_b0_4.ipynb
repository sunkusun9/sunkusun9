{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 01:43:44.967593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743644625.088913    5923 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743644625.118016    5923 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743644625.395026    5923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743644625.395086    5923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743644625.395095    5923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743644625.395101    5923 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2e83d-0d6f-4efc-bed0-2cb3967d86e9",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743644630.021356    5923 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    이미지를 불러옵니다.\n",
    "    Parameters:\n",
    "        filename: str\n",
    "            h5 파일에서 데이터를 불러옵니다.\n",
    "    Returns:\n",
    "        np.ndarray, pd.DataFrame, np.ndarray, \n",
    "        train 이미지, train spot 정보, test 이미지, test spot 정보\n",
    "    \"\"\"\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        # Train 이미지를 불러옵니다.\n",
    "        # 하나의 텐서로 만들기 위해 이미지의 크기를 2000x2000으로 균일하게 만듭니다.\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "        # Test 이미지를 불러옵니다.\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "    # EfficientNet의 형식으로 바꿉니다.\n",
    "    with tf.device('/CPU:0'):\n",
    "        images = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images))\n",
    "    df_spots = pd.concat(spots)\n",
    "    with tf.device('/CPU:0'):\n",
    "        images_test = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images_test))\n",
    "    df_spots_test = pd.concat(spots_test)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, df[targets])\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X, images):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "augmentation_layers = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22c6c30-1da4-4437-9ba1-e81bbe23a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22d774a-5ca2-4a50-bb36-c626fbbf4424",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08aa61c-806d-4c04-b228-132bd9491c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spots['slide'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class TqdmEpochProgress(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.progress_bar = tqdm(total=self.epochs, desc=\"Epochs\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log_str = f\"loss: {logs.get('loss'):.4f}\"\n",
    "        if 'val_loss' in logs:\n",
    "            log_str += f\", val_loss: {logs.get('val_loss'):.4f}\"\n",
    "        self.progress_bar.set_postfix_str(log_str)\n",
    "        self.progress_bar.update(1)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca898ab-8c12-468e-8853-8ab2b9bdcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseHingeLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"pairwise_hinge_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return tf.reduce_sum(\n",
    "            tf.maximum(\n",
    "                0.0, 1.0 - (tf.expand_dims(y_pred, axis=-1) - tf.expand_dims(y_pred, axis=-2))\n",
    "            ) * tf.cast(tf.expand_dims(y_true, axis=-1) > tf.expand_dims(y_true, axis=-2), dtype = tf.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d25-77b2-44c1-bf63-71e9de027b72",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffea29a-6174-4f4d-b698-f48043b903ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_cv_train = create_tf_ds(\n",
    "    df_spots.loc[df_spots['slide'] != 5].pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "ds_valid = create_tf_ds(df_spots.loc[df_spots['slide'] == 5]).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0361f2-c92f-4e18-b538-62b4ea3ff213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 86ms/step - loss: 19073.5957 - my_custom_mse: 19073.5957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step\n",
      "0.1153122224499556\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 17914.1816 - my_custom_mse: 17914.1816\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.1863906538225046\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 16872.3203 - my_custom_mse: 16872.3203\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.23045535287285648\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 16078.5508 - my_custom_mse: 16078.5508\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.3884923481587757\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 15435.9385 - my_custom_mse: 15435.9385\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.43899108423857347\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 14888.4795 - my_custom_mse: 14888.4795\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.4869867459178794\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 14427.6357 - my_custom_mse: 14427.6357\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5073580651772905\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 14008.7275 - my_custom_mse: 14008.7275\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5287405205984833\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 13677.7383 - my_custom_mse: 13677.7383\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5457615973218556\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 13416.0283 - my_custom_mse: 13416.0283\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5584571633531462\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 13184.2109 - my_custom_mse: 13184.2109\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5594870875179341\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 13011.5898 - my_custom_mse: 13011.5898\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5708495593359295\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12850.9248 - my_custom_mse: 12850.9248\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5782665505226482\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12735.8398 - my_custom_mse: 12735.8398\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5765175582428094\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12652.3311 - my_custom_mse: 12652.3311\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.586283049805288\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12561.6016 - my_custom_mse: 12561.6016\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5863419758147163\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12525.2891 - my_custom_mse: 12525.2891\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5885717701714833\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12471.4160 - my_custom_mse: 12471.4160\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5890209742433559\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12419.1758 - my_custom_mse: 12419.1758\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5887895402063266\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12398.6553 - my_custom_mse: 12398.6553\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5901397144223544\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12364.5039 - my_custom_mse: 12364.5039\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5897767643642823\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12328.1934 - my_custom_mse: 12328.1934\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5914967206394753\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12311.2451 - my_custom_mse: 12311.2451\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5881174420987908\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12286.9873 - my_custom_mse: 12286.9873\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5931159048985448\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12240.6191 - my_custom_mse: 12240.6191\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5944515611122498\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12238.5381 - my_custom_mse: 12238.5381\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5921269727403157\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12206.0869 - my_custom_mse: 12206.0869\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5954088952654233\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12174.5645 - my_custom_mse: 12174.5645\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5959016533442646\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12151.1631 - my_custom_mse: 12151.1631\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5939468470314956\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 12118.0488 - my_custom_mse: 12118.0488\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5968299514927923\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = PairwiseHingeLoss(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [PairwiseHingeLoss()]\n",
    ")\n",
    "df_true = df_spots.loc[df_spots['slide'] == 5, targets]\n",
    "for i in range(30):\n",
    "    hist = m.fit(ds_cv_train, epochs = 1)\n",
    "    df_prd = pd.DataFrame(\n",
    "       m.predict(ds_valid), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407dfd-3912-44ff-bb8b-222943e7ef1c",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "과적합을 유의해야하는 데이터셋으로 판단되고 큰 도움은 되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337e0bb0-6ba1-408f-bbc0-c45851d7dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 86ms/step - loss: 11995.6201 - pairwise_hinge_loss: 11995.6201\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step\n",
      "0.6002963380474141 0.8212345117065115\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11908.0615 - pairwise_hinge_loss: 11908.0615\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5968094554895129 0.7898164633285091\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11844.4688 - pairwise_hinge_loss: 11844.4688\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.601015406162465 0.8295621284427014\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 11767.3506 - pairwise_hinge_loss: 11767.3506\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5994918699186993 0.8192455664835954\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11700.7139 - pairwise_hinge_loss: 11700.7139\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.603902780624445 0.8455492408696743\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11635.4600 - pairwise_hinge_loss: 11635.4600\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6058037849286055 0.8477143492033883\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11566.9990 - pairwise_hinge_loss: 11566.9990\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6028720024595204 0.8080375532812616\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11490.7559 - pairwise_hinge_loss: 11490.7559\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6060497369679579 0.8199202316543234\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11451.1230 - pairwise_hinge_loss: 11451.1230\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6042161986745919 0.8236801264047149\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - loss: 11371.4131 - pairwise_hinge_loss: 11371.4131\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6107185557149689 0.8572205151066188\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=PairwiseHingeLoss(),\n",
    "    metrics=[PairwiseHingeLoss()],\n",
    ")\n",
    "for i in range(10):\n",
    "    hist = m.fit(ds_cv_train, epochs=1)\n",
    "    df_prd =  pd.DataFrame(\n",
    "       m.predict(ds_valid), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab58473-e4a2-4138-9981-0ded6a2f548b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fe4a34-f38a-44f7-9802-a4e7d9186cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743644676.783996    6374 service.cc:152] XLA service 0x7f63b8003870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743644676.784018    6374 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "I0000 00:00:1743644680.171411    6374 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-04-03 01:44:47.656004: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 01:44:47.777824: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 01:44:48.137616: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 01:44:48.258546: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1743644701.847729    6374 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 208ms/step - loss: 19932.4590 - pairwise_hinge_loss: 19932.4590\n",
      "Epoch 2/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 85ms/step - loss: 18462.4453 - pairwise_hinge_loss: 18462.4453\n",
      "Epoch 3/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 17187.1016 - pairwise_hinge_loss: 17187.1016\n",
      "Epoch 4/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 16100.1465 - pairwise_hinge_loss: 16100.1465\n",
      "Epoch 5/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 15243.6016 - pairwise_hinge_loss: 15243.6016\n",
      "Epoch 6/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 14551.7803 - pairwise_hinge_loss: 14551.7803\n",
      "Epoch 7/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - loss: 14015.3408 - pairwise_hinge_loss: 14015.3408\n",
      "Epoch 8/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 13547.2041 - pairwise_hinge_loss: 13547.2041\n",
      "Epoch 9/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 13216.1709 - pairwise_hinge_loss: 13216.1709\n",
      "Epoch 10/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12931.5088 - pairwise_hinge_loss: 12931.5088\n",
      "Epoch 11/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12733.2119 - pairwise_hinge_loss: 12733.2119\n",
      "Epoch 12/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12553.5615 - pairwise_hinge_loss: 12553.5615\n",
      "Epoch 13/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12402.1201 - pairwise_hinge_loss: 12402.1201\n",
      "Epoch 14/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12303.7148 - pairwise_hinge_loss: 12303.7148\n",
      "Epoch 15/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12209.1924 - pairwise_hinge_loss: 12209.1924\n",
      "Epoch 16/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 12144.2842 - pairwise_hinge_loss: 12144.2842\n",
      "Epoch 17/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 12080.9658 - pairwise_hinge_loss: 12080.9658\n",
      "Epoch 18/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 12050.9941 - pairwise_hinge_loss: 12050.9941\n",
      "Epoch 19/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 12011.2158 - pairwise_hinge_loss: 12011.2158\n",
      "Epoch 20/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11989.2334 - pairwise_hinge_loss: 11989.2334\n",
      "Epoch 21/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11960.1416 - pairwise_hinge_loss: 11960.1416\n",
      "Epoch 22/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 86ms/step - loss: 11926.1064 - pairwise_hinge_loss: 11926.1064\n",
      "Epoch 23/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11896.1680 - pairwise_hinge_loss: 11896.1680\n",
      "Epoch 24/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11869.0596 - pairwise_hinge_loss: 11869.0596\n",
      "Epoch 25/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11833.2695 - pairwise_hinge_loss: 11833.2695\n",
      "Epoch 26/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11817.4980 - pairwise_hinge_loss: 11817.4980\n",
      "Epoch 27/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11794.6475 - pairwise_hinge_loss: 11794.6475\n",
      "Epoch 28/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11751.5283 - pairwise_hinge_loss: 11751.5283\n",
      "Epoch 29/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11735.8135 - pairwise_hinge_loss: 11735.8135\n",
      "Epoch 30/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11713.2812 - pairwise_hinge_loss: 11713.2812\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_train = create_tf_ds(\n",
    "    df_spots.pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = PairwiseHingeLoss(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [PairwiseHingeLoss()]\n",
    ")\n",
    "hist = m.fit(ds_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68bab663-0dce-437c-97f1-58c476965cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 86ms/step - loss: 11672.7324 - pairwise_hinge_loss: 11672.7324\n",
      "Epoch 2/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11593.0713 - pairwise_hinge_loss: 11593.0713\n",
      "Epoch 3/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11504.4404 - pairwise_hinge_loss: 11504.4404\n",
      "Epoch 4/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11434.9365 - pairwise_hinge_loss: 11434.9365\n",
      "Epoch 5/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11370.5947 - pairwise_hinge_loss: 11370.5947\n",
      "Epoch 6/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11299.1533 - pairwise_hinge_loss: 11299.1533\n",
      "Epoch 7/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11238.5781 - pairwise_hinge_loss: 11238.5781\n",
      "Epoch 8/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11165.2568 - pairwise_hinge_loss: 11165.2568\n",
      "Epoch 9/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11114.5586 - pairwise_hinge_loss: 11114.5586\n",
      "Epoch 10/10\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 87ms/step - loss: 11043.5322 - pairwise_hinge_loss: 11043.5322\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=PairwiseHingeLoss(),\n",
    "    metrics=[PairwiseHingeLoss()],\n",
    ")\n",
    "hist = m.fit(ds_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8872b7f4-5a81-4cbe-bf0e-860c1fecae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/eff_b0_4.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m.get_weights(), 'model/eff_b0_4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)\n",
    "\n",
    "df_submission = pd.DataFrame(\n",
    "    m.predict(\n",
    "        ds_test.map(lambda X: proc_images(X)).batch(32)\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>C31</th>\n",
       "      <th>C32</th>\n",
       "      <th>C33</th>\n",
       "      <th>C34</th>\n",
       "      <th>C35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.059851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128045</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.204422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.076468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.137513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.039391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.158754</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.120627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032568</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.114594</td>\n",
       "      <td>0.134391</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.124492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.054116</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.080666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>0.076367</td>\n",
       "      <td>0.124544</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>0.089570</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>0.134732</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.135976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.085672</td>\n",
       "      <td>0.118656</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.114055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>0.120247</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.106010</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.279060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.060093</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.097737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.087320</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043730</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.084443</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.087110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.151359</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.163655</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.044984</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.041145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.075038</td>\n",
       "      <td>0.084462</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.044275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        C1        C2        C3        C4        C5        C6  \\\n",
       "0        0  0.106880  0.117950  0.103375  0.005968  0.003798  0.024129   \n",
       "1        1  0.128045  0.116623  0.138590  0.010258  0.007435  0.050321   \n",
       "2        2  0.099630  0.098611  0.100010  0.008563  0.018887  0.026819   \n",
       "3        3  0.180319  0.137755  0.158754  0.006162  0.006356  0.041420   \n",
       "4        4  0.087845  0.145078  0.084427  0.001418  0.001762  0.010620   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2083  2083  0.076367  0.124544  0.080420  0.005161  0.014594  0.023217   \n",
       "2084  2084  0.109420  0.134732  0.117060  0.002985  0.003336  0.030402   \n",
       "2085  2085  0.149589  0.089491  0.120247  0.006303  0.009186  0.106010   \n",
       "2086  2086  0.088822  0.163909  0.087320  0.001273  0.002170  0.009971   \n",
       "2087  2087  0.151359  0.098457  0.163655  0.015520  0.044984  0.013516   \n",
       "\n",
       "            C7        C8        C9  ...       C26       C27       C28  \\\n",
       "0     0.035309  0.008406  0.098681  ...  0.013731  0.019819  0.012259   \n",
       "1     0.042165  0.009597  0.204422  ...  0.015731  0.056274  0.016234   \n",
       "2     0.027433  0.006014  0.137513  ...  0.006670  0.036991  0.006439   \n",
       "3     0.081333  0.030389  0.120627  ...  0.032568  0.036748  0.034174   \n",
       "4     0.054116  0.025442  0.053148  ...  0.036336  0.012387  0.023168   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2083  0.056135  0.016682  0.076528  ...  0.019992  0.027192  0.016148   \n",
       "2084  0.056009  0.022790  0.135976  ...  0.039139  0.036089  0.032287   \n",
       "2085  0.041300  0.011640  0.279060  ...  0.021469  0.122370  0.035616   \n",
       "2086  0.064393  0.025293  0.044465  ...  0.043730  0.010352  0.019291   \n",
       "2087  0.034210  0.005261  0.041145  ...  0.006100  0.015927  0.006985   \n",
       "\n",
       "           C29       C30       C31       C32       C33       C34       C35  \n",
       "0     0.018550  0.002482  0.061982  0.069548  0.009430  0.010013  0.059851  \n",
       "1     0.026071  0.001425  0.072266  0.080541  0.011042  0.010376  0.076468  \n",
       "2     0.011987  0.001200  0.062143  0.067901  0.003298  0.007506  0.039391  \n",
       "3     0.035257  0.004906  0.114594  0.134391  0.015988  0.024055  0.124492  \n",
       "4     0.025999  0.013443  0.077650  0.096791  0.019800  0.012882  0.080666  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2083  0.040179  0.002422  0.089227  0.089570  0.010097  0.009481  0.072841  \n",
       "2084  0.035312  0.006070  0.085672  0.118656  0.019103  0.013551  0.114055  \n",
       "2085  0.024045  0.000779  0.060093  0.092103  0.008761  0.014749  0.097737  \n",
       "2086  0.025303  0.020673  0.084443  0.089774  0.022668  0.014188  0.087110  \n",
       "2087  0.010253  0.001238  0.075038  0.084462  0.002773  0.008973  0.044275  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c4af3-6440-4902-9667-1083ee40ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
