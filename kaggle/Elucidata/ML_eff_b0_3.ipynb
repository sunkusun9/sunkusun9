{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ca6e1c-6c6c-40b2-afa8-a36faf0cf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2e83d-0d6f-4efc-bed0-2cb3967d86e9",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9d49ae-5b81-440d-9553-2b3c157d9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    이미지를 불러옵니다.\n",
    "    Parameters:\n",
    "        filename: str\n",
    "            h5 파일에서 데이터를 불러옵니다.\n",
    "    Returns:\n",
    "        np.ndarray, pd.DataFrame, np.ndarray, \n",
    "        train 이미지, train spot 정보, test 이미지, test spot 정보\n",
    "    \"\"\"\n",
    "    images, images_test = list(), list()\n",
    "    spots, spots_test = list(), list()\n",
    "    with h5py.File(filename, \"r\") as h5file:\n",
    "        train_images = h5file[\"images/Train\"]\n",
    "        train_spots = h5file[\"spots/Train\"]\n",
    "    \n",
    "        num_train_slides = len(train_images)\n",
    "        # Train 이미지를 불러옵니다.\n",
    "        # 하나의 텐서로 만들기 위해 이미지의 크기를 2000x2000으로 균일하게 만듭니다.\n",
    "        for i, slide_name in enumerate(train_images.keys()):\n",
    "            image = np.array(train_images[slide_name])\n",
    "            p1 = 2000 - image.shape[0]\n",
    "            p2 = 2000 - image.shape[1]\n",
    "            images.append(\n",
    "                np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge')\n",
    "            )\n",
    "            spots.append(pd.DataFrame(np.array(train_spots[slide_name])).assign(slide = i))\n",
    "        # Test 이미지를 불러옵니다.\n",
    "        test_images = h5file[\"images/Test\"]\n",
    "        test_spots = h5file[\"spots/Test\"]\n",
    "        sample = 'S_7'\n",
    "        image = np.array(test_images[sample])\n",
    "        p1 = 2000 - image.shape[0]\n",
    "        p2 = 2000 - image.shape[1]\n",
    "        images_test.append(np.pad(image, [(0, p1), (0, p2), (0, 0)], 'edge'))\n",
    "        spots_test.append(pd.DataFrame(np.array(test_spots[sample])).assign(slide = 0))\n",
    "    # EfficientNet의 형식으로 바꿉니다.\n",
    "    with tf.device('/CPU:0'):\n",
    "        images = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images))\n",
    "    df_spots = pd.concat(spots)\n",
    "    with tf.device('/CPU:0'):\n",
    "        images_test = tf.constant(tf.keras.applications.efficientnet.preprocess_input(images_test))\n",
    "    df_spots_test = pd.concat(spots_test)\n",
    "    return images, df_spots, images_test, df_spots_test\n",
    "\n",
    "def make_img_proc_info(df, img_with, img_height):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.assign(\n",
    "        left = lambda x: x['x'] - img_width // 2,\n",
    "        right = lambda x: x['x'] + img_width // 2,\n",
    "        top = lambda x: x['y'] - img_height // 2,\n",
    "        bottom = lambda x: x['y'] + img_height // 2,\n",
    "        lpad = lambda x: -(x['left'].where(x['left'] < 0, 0)),\n",
    "        rpad = lambda x: -(2000 - x['right']).where(x['right'] > 2000, 0),\n",
    "        tpad = lambda x: -(x['top'].where(x['top'] < 0, 0)),\n",
    "        bpad = lambda x: -(2000 - x['bottom']).where(x['bottom'] > 2000, 0)\n",
    "    ).assign(\n",
    "        left = lambda x: x['left'].clip(0, 2000),\n",
    "        right = lambda x: x['right'].clip(0, 2000),\n",
    "        top = lambda x: x['top'].clip(0, 2000),\n",
    "        bottom = lambda x: x['bottom'].clip(0, 2000),\n",
    "    )\n",
    "\n",
    "def create_tf_ds(df):\n",
    "    if (pd.Series(targets).isin(df.columns)).all():\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "            }, df[targets])\n",
    "        )\n",
    "    else:\n",
    "        return tf.data.Dataset.from_tensor_slices({\n",
    "            i: df[i] for i in ['left', 'right', 'top', 'bottom', 'slide', 'lpad', 'rpad', 'tpad', 'bpad']\n",
    "        })\n",
    "\n",
    "def proc_images(X, images):\n",
    "    return tf.pad(\n",
    "        images[X['slide'], X['left']:X['right'], X['top']:X['bottom'], :], \n",
    "        paddings = [(X['lpad'], X['rpad']), (X['tpad'], X['bpad']), (0, 0)],\n",
    "        constant_values=1\n",
    "    )\n",
    "\n",
    "augmentation_layers = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "images, df_spots, images_test, df_spots_test = load_data(\"data/elucidata_ai_challenge_data.h5\")\n",
    "targets = [i for i in df_spots.columns if i.startswith('C')]\n",
    "\n",
    "target_proc = FunctionTransformer(np.log, np.exp)\n",
    "target_proc.fit(df_spots[targets])\n",
    "df_spots[targets] = target_proc.transform(df_spots[targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22c6c30-1da4-4437-9ba1-e81bbe23a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "df_spots = make_img_proc_info(df_spots, img_width, img_height)\n",
    "df_spots_test = make_img_proc_info(df_spots_test, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22d774a-5ca2-4a50-bb36-c626fbbf4424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08aa61c-806d-4c04-b228-132bd9491c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spots['slide'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "class TqdmEpochProgress(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.progress_bar = tqdm(total=self.epochs, desc=\"Epochs\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log_str = f\"loss: {logs.get('loss'):.4f}\"\n",
    "        if 'val_loss' in logs:\n",
    "            log_str += f\", val_loss: {logs.get('val_loss'):.4f}\"\n",
    "        self.progress_bar.set_postfix_str(log_str)\n",
    "        self.progress_bar.update(1)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c7d25-77b2-44c1-bf63-71e9de027b72",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffea29a-6174-4f4d-b698-f48043b903ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_cv_train = create_tf_ds(\n",
    "    df_spots.loc[df_spots['slide'] != 5].pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "ds_valid = create_tf_ds(df_spots.loc[df_spots['slide'] == 5]).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0361f2-c92f-4e18-b538-62b4ea3ff213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 86ms/step - cosine_similarity: 0.1901 - loss: -0.1901\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 348ms/step\n",
      "-0.1828542392566783 1.2145490042251401\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - cosine_similarity: 0.6156 - loss: -0.6156\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "-0.06805868688938992 0.8448595119321661\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - cosine_similarity: 0.7499 - loss: -0.7499\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.13173549907767987 0.5995709950362964\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - cosine_similarity: 0.8234 - loss: -0.8234\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.26317380610780905 0.49243702520866844\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.8582 - loss: -0.8582\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.3736353077816493 0.437604775009259\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.8784 - loss: -0.8784\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.4623778779804605 0.40529328739359477\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.8903 - loss: -0.8903\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5027635444421671 0.385988465718103\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.8983 - loss: -0.8983\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "0.5351378356220537 0.3775419937388995\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9034 - loss: -0.9034\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5586493133838901 0.363171675283739\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9075 - loss: -0.9075\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5692448930791829 0.35852832913695504\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9104 - loss: -0.9104\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5810147229623557 0.35555874932540654\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9125 - loss: -0.9125\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5927632028421125 0.34674755190146683\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9141 - loss: -0.9141\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.5955848192935711 0.34292762439460256\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9162 - loss: -0.9162\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6085647673703629 0.33368643635311973\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9173 - loss: -0.9173\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.5996507139441143 0.3298692763565866\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9183 - loss: -0.9183\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6143027942884471 0.330665942248569\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9188 - loss: -0.9188\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6206437453029994 0.32784833979525696\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9196 - loss: -0.9196\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6207641593222655 0.3269776043376797\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9199 - loss: -0.9199\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6111874017899843 0.3318016181538005\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9206 - loss: -0.9206\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.614445412311266 0.32900368682630765\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9211 - loss: -0.9211\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6166026166564187 0.33209653589611104\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9215 - loss: -0.9215\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6118296098927376 0.33223621240131657\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9220 - loss: -0.9220\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6106767097082736 0.32776186747485664\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9223 - loss: -0.9223\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6210989273758284 0.326213265129931\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9225 - loss: -0.9225\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6157187265149964 0.32732219748433716\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9232 - loss: -0.9232\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6171756507481042 0.3211488616932302\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9236 - loss: -0.9236\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6232552777208445 0.32369030533421195\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9241 - loss: -0.9241\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6111856937897111 0.3195678673141957\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9243 - loss: -0.9243\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6194754731160758 0.3186420477964734\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9247 - loss: -0.9247\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6193516430962629 0.31795638386149766\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9254 - loss: -0.9254\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6151132404181185 0.31841150875231666\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9254 - loss: -0.9254\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6152584204413473 0.3189927888514668\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9261 - loss: -0.9261\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.609095955455353 0.3166612859780895\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9262 - loss: -0.9262\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "0.6123821479811438 0.31626569841640884\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 87ms/step - cosine_similarity: 0.9264 - loss: -0.9264\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "0.6084007993441279 0.3162472025674859\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.CosineSimilarity(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.CosineSimilarity()]\n",
    ")\n",
    "df_true = pd.DataFrame(\n",
    "    target_proc.inverse_transform(\n",
    "        df_spots.loc[df_spots['slide'] == 5, targets]\n",
    "    ), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    ")\n",
    "for i in range(35):\n",
    "    hist = m.fit(ds_cv_train, epochs = 1)\n",
    "    df_prd = pd.DataFrame(\n",
    "        target_proc.inverse_transform(m.predict(ds_valid)), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27407dfd-3912-44ff-bb8b-222943e7ef1c",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "과적합을 유의해야하는 데이터셋으로 판단되고 큰 도움은 되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337e0bb0-6ba1-408f-bbc0-c45851d7dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninputs = tf.keras.Input(shape = input_shape)\\nx = enet(inputs, training = True)\\nx = tf.keras.layers.Dropout(0.2)(x)\\nx = d1(x)\\noutputs = d2(x)\\nm = tf.keras.models.Model(inputs, outputs)\\nm.compile(\\n    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\\n    loss=tf.keras.losses.CosineSimilarity(),\\n    metrics=[tf.keras.metrics.CosineSimilarity()],\\n)\\nfor i in range(10):\\n    hist = m.fit(ds_cv_train, epochs=1)\\n    df_prd = pd.DataFrame(\\n        target_proc.inverse_transform(m.predict(ds_valid)), index = df_spots[df_spots['slide'] == 5].index, columns = targets\\n    )\\n    print(\\n        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\\n        mean_squared_error(df_true.stack(), df_prd.stack())\\n    )\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = True)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = d1(x)\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=tf.keras.losses.CosineSimilarity(),\n",
    "    metrics=[tf.keras.metrics.CosineSimilarity()],\n",
    ")\n",
    "for i in range(10):\n",
    "    hist = m.fit(ds_cv_train, epochs=1)\n",
    "    df_prd = pd.DataFrame(\n",
    "        target_proc.inverse_transform(m.predict(ds_valid)), index = df_spots[df_spots['slide'] == 5].index, columns = targets\n",
    "    )\n",
    "    print(\n",
    "        df_true.apply(lambda x: spearmanr(x, df_prd.loc[x.name])[0], axis=1).mean(),\n",
    "        mean_squared_error(df_true.stack(), df_prd.stack())\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab58473-e4a2-4138-9981-0ded6a2f548b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c78e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 165ms/step - cosine_similarity: -0.0657 - loss: 0.0657\n",
      "Epoch 2/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - cosine_similarity: 0.1597 - loss: -0.1597\n",
      "Epoch 3/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - cosine_similarity: 0.3310 - loss: -0.3310\n",
      "Epoch 4/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - cosine_similarity: 0.4517 - loss: -0.4517\n",
      "Epoch 5/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - cosine_similarity: 0.5387 - loss: -0.5387\n",
      "Epoch 6/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.6025 - loss: -0.6025\n",
      "Epoch 7/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - cosine_similarity: 0.6504 - loss: -0.6504\n",
      "Epoch 8/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - cosine_similarity: 0.6870 - loss: -0.6870\n",
      "Epoch 9/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 86ms/step - cosine_similarity: 0.7123 - loss: -0.7123\n",
      "Epoch 10/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - cosine_similarity: 0.7327 - loss: -0.7327\n",
      "Epoch 11/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.7468 - loss: -0.7468\n",
      "Epoch 12/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.7602 - loss: -0.7602\n",
      "Epoch 13/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 85ms/step - cosine_similarity: 0.7700 - loss: -0.7700\n",
      "Epoch 14/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.7767 - loss: -0.7767\n",
      "Epoch 15/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.7820 - loss: -0.7820\n",
      "Epoch 16/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.7872 - loss: -0.7872\n",
      "Epoch 17/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 83ms/step - cosine_similarity: 0.7898 - loss: -0.7898\n",
      "Epoch 18/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.7929 - loss: -0.7929\n",
      "Epoch 19/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - cosine_similarity: 0.7947 - loss: -0.7947\n",
      "Epoch 20/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - cosine_similarity: 0.7977 - loss: -0.7977\n",
      "Epoch 21/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - cosine_similarity: 0.7989 - loss: -0.7989\n",
      "Epoch 22/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.8012 - loss: -0.8012\n",
      "Epoch 23/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.8037 - loss: -0.8037\n",
      "Epoch 24/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - cosine_similarity: 0.8049 - loss: -0.8049\n",
      "Epoch 25/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.8068 - loss: -0.8068\n",
      "Epoch 26/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.8089 - loss: -0.8089\n",
      "Epoch 27/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - cosine_similarity: 0.8105 - loss: -0.8105\n",
      "Epoch 28/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 84ms/step - cosine_similarity: 0.8123 - loss: -0.8123\n",
      "Epoch 29/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - cosine_similarity: 0.8141 - loss: -0.8141\n",
      "Epoch 30/30\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - cosine_similarity: 0.8156 - loss: -0.8156\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "ds_train = create_tf_ds(\n",
    "    df_spots.pipe(\n",
    "        lambda x: pd.concat([\n",
    "            x, x.sample(n = batch_size - (len(x) % batch_size))\n",
    "        ])\n",
    "    )\n",
    ").shuffle(5000).map(\n",
    "    lambda X, Y: (proc_images(X, images), Y)\n",
    ").map(\n",
    "    lambda X, Y: (data_augmentation(X), Y)\n",
    ").batch(batch_size).prefetch(tf.data.AUTOTUNE).cache()\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "enet = tf.keras.applications.EfficientNetB0(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet',\n",
    "    input_shape = input_shape,\n",
    "    pooling = 'avg'\n",
    ")\n",
    "inputs = tf.keras.Input(shape = input_shape)\n",
    "x = enet(inputs, training = False)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "d1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_initializer = 'HeUniform')\n",
    "x = d1(x)\n",
    "d2 = tf.keras.layers.Dense(len(targets))\n",
    "outputs = d2(x)\n",
    "m = tf.keras.models.Model(inputs, outputs)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=3e-6,\n",
    "    decay_steps=5000,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    loss = tf.keras.losses.CosineSimilarity(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    metrics = [tf.keras.metrics.CosineSimilarity()]\n",
    ")\n",
    "hist = m.fit(ds_train, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8872b7f4-5a81-4cbe-bf0e-860c1fecae0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/eff_b0_3.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m.get_weights(), 'model/eff_b0_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324394a4-4a9d-4ac1-a7ab-e923c2c3b5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/target_proc_3.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(target_proc, 'model/target_proc_3.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f334d99-f986-4903-a83c-b629a34b80a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "ds_test = create_tf_ds(df_spots_test)\n",
    "\n",
    "df_submission = pd.DataFrame(\n",
    "    np.exp(\n",
    "        m.predict(\n",
    "            ds_test.map(lambda X: proc_images(X)).batch(32)\n",
    "        )\n",
    "    ), columns = targets\n",
    ").reset_index().rename(columns = {'index': 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78ca52ce-c633-4561-bcc8-bef388c17d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C26</th>\n",
       "      <th>C27</th>\n",
       "      <th>C28</th>\n",
       "      <th>C29</th>\n",
       "      <th>C30</th>\n",
       "      <th>C31</th>\n",
       "      <th>C32</th>\n",
       "      <th>C33</th>\n",
       "      <th>C34</th>\n",
       "      <th>C35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.106880</td>\n",
       "      <td>0.117950</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.061982</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.059851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128045</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.204422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.056274</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.026071</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.072266</td>\n",
       "      <td>0.080541</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.010376</td>\n",
       "      <td>0.076468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099630</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.137513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.039391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>0.137755</td>\n",
       "      <td>0.158754</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.081333</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.120627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032568</td>\n",
       "      <td>0.036748</td>\n",
       "      <td>0.034174</td>\n",
       "      <td>0.035257</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.114594</td>\n",
       "      <td>0.134391</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.124492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.087845</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.054116</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036336</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.025999</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.077650</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.080666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2083</td>\n",
       "      <td>0.076367</td>\n",
       "      <td>0.124544</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.089227</td>\n",
       "      <td>0.089570</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2084</td>\n",
       "      <td>0.109420</td>\n",
       "      <td>0.134732</td>\n",
       "      <td>0.117060</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.030402</td>\n",
       "      <td>0.056009</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.135976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039139</td>\n",
       "      <td>0.036089</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>0.085672</td>\n",
       "      <td>0.118656</td>\n",
       "      <td>0.019103</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>0.114055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>2085</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.089491</td>\n",
       "      <td>0.120247</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.106010</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.279060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.122370</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.060093</td>\n",
       "      <td>0.092103</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>0.097737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>0.088822</td>\n",
       "      <td>0.163909</td>\n",
       "      <td>0.087320</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.064393</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.044465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043730</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>0.084443</td>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.087110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>0.151359</td>\n",
       "      <td>0.098457</td>\n",
       "      <td>0.163655</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.044984</td>\n",
       "      <td>0.013516</td>\n",
       "      <td>0.034210</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.041145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.075038</td>\n",
       "      <td>0.084462</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.044275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2088 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        C1        C2        C3        C4        C5        C6  \\\n",
       "0        0  0.106880  0.117950  0.103375  0.005968  0.003798  0.024129   \n",
       "1        1  0.128045  0.116623  0.138590  0.010258  0.007435  0.050321   \n",
       "2        2  0.099630  0.098611  0.100010  0.008563  0.018887  0.026819   \n",
       "3        3  0.180319  0.137755  0.158754  0.006162  0.006356  0.041420   \n",
       "4        4  0.087845  0.145078  0.084427  0.001418  0.001762  0.010620   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "2083  2083  0.076367  0.124544  0.080420  0.005161  0.014594  0.023217   \n",
       "2084  2084  0.109420  0.134732  0.117060  0.002985  0.003336  0.030402   \n",
       "2085  2085  0.149589  0.089491  0.120247  0.006303  0.009186  0.106010   \n",
       "2086  2086  0.088822  0.163909  0.087320  0.001273  0.002170  0.009971   \n",
       "2087  2087  0.151359  0.098457  0.163655  0.015520  0.044984  0.013516   \n",
       "\n",
       "            C7        C8        C9  ...       C26       C27       C28  \\\n",
       "0     0.035309  0.008406  0.098681  ...  0.013731  0.019819  0.012259   \n",
       "1     0.042165  0.009597  0.204422  ...  0.015731  0.056274  0.016234   \n",
       "2     0.027433  0.006014  0.137513  ...  0.006670  0.036991  0.006439   \n",
       "3     0.081333  0.030389  0.120627  ...  0.032568  0.036748  0.034174   \n",
       "4     0.054116  0.025442  0.053148  ...  0.036336  0.012387  0.023168   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2083  0.056135  0.016682  0.076528  ...  0.019992  0.027192  0.016148   \n",
       "2084  0.056009  0.022790  0.135976  ...  0.039139  0.036089  0.032287   \n",
       "2085  0.041300  0.011640  0.279060  ...  0.021469  0.122370  0.035616   \n",
       "2086  0.064393  0.025293  0.044465  ...  0.043730  0.010352  0.019291   \n",
       "2087  0.034210  0.005261  0.041145  ...  0.006100  0.015927  0.006985   \n",
       "\n",
       "           C29       C30       C31       C32       C33       C34       C35  \n",
       "0     0.018550  0.002482  0.061982  0.069548  0.009430  0.010013  0.059851  \n",
       "1     0.026071  0.001425  0.072266  0.080541  0.011042  0.010376  0.076468  \n",
       "2     0.011987  0.001200  0.062143  0.067901  0.003298  0.007506  0.039391  \n",
       "3     0.035257  0.004906  0.114594  0.134391  0.015988  0.024055  0.124492  \n",
       "4     0.025999  0.013443  0.077650  0.096791  0.019800  0.012882  0.080666  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2083  0.040179  0.002422  0.089227  0.089570  0.010097  0.009481  0.072841  \n",
       "2084  0.035312  0.006070  0.085672  0.118656  0.019103  0.013551  0.114055  \n",
       "2085  0.024045  0.000779  0.060093  0.092103  0.008761  0.014749  0.097737  \n",
       "2086  0.025303  0.020673  0.084443  0.089774  0.022668  0.014188  0.087110  \n",
       "2087  0.010253  0.001238  0.075038  0.084462  0.002773  0.008973  0.044275  \n",
       "\n",
       "[2088 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c4af3-6440-4902-9667-1083ee40ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
