{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a2a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lifelines\n",
      "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.13.1)\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines) (3.7.5)\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines) (1.7.0)\n",
      "Collecting autograd-gamma>=0.3 (from lifelines)\n",
      "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting formulaic>=0.2.2 (from lifelines)\n",
      "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
      "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines) (2.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->lifelines) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->lifelines) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->lifelines) (2024.2.0)\n",
      "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: autograd-gamma\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=0d9ec25d60681f13e55075b0cc937276a73924497a4a0c49353b17247057e72f\n",
      "  Stored in directory: /root/.cache/pip/wheels/25/cc/e0/ef2969164144c899fedb22b338f6703e2b9cf46eeebf254991\n",
      "Successfully built autograd-gamma\n",
      "Installing collected packages: interface-meta, formulaic, autograd-gamma, lifelines\n",
      "Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7bb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "numpy 1.26.4\n",
      "pandas 2.2.3\n",
      "polars 1.9.0\n",
      "matplotlib 3.7.5\n",
      "seaborn 0.12.2\n",
      "lifelines 0.30.0\n",
      "sklearn 1.2.2\n",
      "lightgbm 4.5.0\n",
      "xgboost 2.0.3\n",
      "catboost 1.2.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import pandas.api.types\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "import lifelines\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [np, pd, pl, mpl, sns, lifelines, sklearn, lgb, xgb, cb]:\n",
    "    try:\n",
    "        print(i.__name__, i.__version__)\n",
    "    except:\n",
    "        print(i.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e2dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dproc, sgutil, sgpp, sgml, custpp\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate, KFold, ShuffleSplit, train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7312c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "model_path = 'model'\n",
    "\n",
    "p3 =joblib.load(os.path.join(model_path, 'p3.joblib'))\n",
    "df_train = p3.transform([os.path.join(data_path, 'train.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a576107",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bool = ['graft_type', 'prod_type']\n",
    "X_tri = [\n",
    "    'arrhythmia', 'cardiac', 'diabetes', 'hepatic_mild', 'hepatic_severe',\n",
    "    'in_vivo_tcd', 'melphalan_dose', 'mrd_hct', 'obesity', 'peptic_ulcer',\n",
    "    'prior_tumor', 'psych_disturb', 'pulm_moderate', 'pulm_severe', 'renal_issue',\n",
    "    'rheum_issue', 'rituximab', 'vent_hist'\n",
    "]\n",
    "X_nom = [\n",
    "    'cmv_status', 'conditioning_intensity', 'cyto_score', 'cyto_score_detail', 'donor_related',\n",
    "    'dri_score', 'ethnicity', 'gvhd_proph', 'prim_disease_hct', 'race_group', 'sex_match',\n",
    "    'tbi_status', 'tce_div_match', 'tce_imm_match', 'tce_match'\n",
    "]\n",
    "X_na = [\n",
    "    'arrhythmia_na', 'cardiac_na', 'diabetes_na', 'hepatic_mild_na', 'hepatic_severe_na',\n",
    "    'obesity_na', 'peptic_ulcer_na', 'prior_tumor_na', 'psych_disturb_na', 'pulm_moderate_na',\n",
    "    'pulm_severe_na', 'renal_issue_na', 'rheum_issue_na'\n",
    "]\n",
    "X_cont = ['age_at_hct', 'donor_age']\n",
    "X_int = [\n",
    "    'comorbidity_score', 'hla_high_res_10', 'hla_high_res_6', 'hla_high_res_8', 'hla_low_res_10',\n",
    "    'hla_low_res_6', 'hla_low_res_8', 'hla_match_a_high', 'hla_match_a_low', 'hla_match_b_high',\n",
    "    'hla_match_b_low', 'hla_match_drb1_low', 'hla_match_c_high', 'hla_match_c_low', 'hla_match_dqb1_high', 'hla_match_dqb1_low',\n",
    "    'hla_match_drb1_high', 'hla_nmdp_6', 'karnofsky_score', 'year_hct'\n",
    "]\n",
    "X_all = X_tri + X_cont + X_int + X_na + X_bool + X_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "446c2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(df, prds):\n",
    "    return df.groupby('race_group', observed=True).apply(\n",
    "        lambda x: concordance_index(x['efs_time'], -prds.loc[x.index], x['efs']), include_groups=False\n",
    "    ).pipe(\n",
    "        lambda x: float(x.mean() - x.std(ddof=0))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a74d978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskModel(tf.keras.Model):\n",
    "    def __init__(self, emb_cols, cont_var, d_layers , **argv):\n",
    "        super().__init__()\n",
    "        self.emb_layers = {\n",
    "            v: tf.keras.layers.Embedding(c, s, name=v) for v, c, s in emb_cols\n",
    "        }\n",
    "        self.cc = tf.keras.layers.Concatenate(axis=-1)\n",
    "        self.d_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(**params) for params in d_layers\n",
    "        ])\n",
    "        self.cont_var = cont_var\n",
    "        #self.sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "        self.eps = 1e-7\n",
    "\n",
    "    def __call__(self, X):\n",
    "        #print(X)\n",
    "        cc_list = [tf.squeeze(v(X[k]), axis=-2) for k, v in self.emb_layers.items()] + [X[self.cont_var]]\n",
    "        X_cc = self.cc(cc_list)\n",
    "        return self.d_model(X_cc)\n",
    "    def compute_loss(self, X, y, y_pred, sample_weight):\n",
    "        sz = tf.shape(y)[0]\n",
    "        A = tf.reshape(tf.repeat(y[:, 0], sz), (-1, sz))\n",
    "        B = tf.transpose(A)\n",
    "        C = tf.cast(A < B, dtype=tf.float32)\n",
    "        A_prd = tf.reshape(tf.repeat(y_pred, sz), (-1, sz))\n",
    "        B_prd = tf.transpose(A_prd)\n",
    "        hinge_loss = tf.keras.ops.relu(1 - (A_prd - B_prd))\n",
    "        D = tf.reshape(tf.repeat(y[:, 1], sz), (-1, sz))\n",
    "        mask = C * D\n",
    "        loss_ = tf.reduce_sum(tf.reduce_sum(mask * hinge_loss, axis=-1) / (tf.reduce_sum(mask, axis = -1) + self.eps))\n",
    "        loss_ = tf.reduce_sum(loss_) / (tf.reduce_sum(y[:, 1]) + self.eps)\n",
    "        return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "344f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sgnn\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def to_tf_dataset(X, Y=None, sample_weights=None, cat=[], cont='Cont'):\n",
    "    d = {}\n",
    "    for i, n in enumerate(cat):\n",
    "        d[n] = np.expand_dims(X.iloc[:, i], axis=-1)\n",
    "    if cont is not None:\n",
    "        d[cont] =  X.iloc[:, len(cat):].astype('float32')\n",
    "    if Y is None:\n",
    "        return tf.data.Dataset.from_tensor_slices(d)\n",
    "    else:\n",
    "        if type(Y) == pd.Series or type(Y) == pd.DataFrame:\n",
    "            if sample_weights is None:\n",
    "                return tf.data.Dataset.from_tensor_slices((d, Y.values))\n",
    "            else:\n",
    "                return tf.data.Dataset.from_tensor_slices((d, Y.values, sample_weights.values))\n",
    "        else:\n",
    "            if sample_weights is None:\n",
    "                return tf.data.Dataset.from_tensor_slices((d, Y))\n",
    "            else:\n",
    "                return tf.data.Dataset.from_tensor_slices((d, Y, sample_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9de0ecc2-bb7c-451d-afee-1456b2f793d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 (cmv_status, 5, 3)\n",
       "1     (conditioning_intensity, 7, 3)\n",
       "2                 (cyto_score, 8, 3)\n",
       "3          (cyto_score_detail, 6, 3)\n",
       "4              (donor_related, 4, 2)\n",
       "5                 (dri_score, 11, 4)\n",
       "6                  (ethnicity, 4, 2)\n",
       "7                (gvhd_proph, 17, 4)\n",
       "8          (prim_disease_hct, 18, 4)\n",
       "9                 (race_group, 6, 3)\n",
       "10                 (sex_match, 5, 3)\n",
       "11                (tbi_status, 8, 3)\n",
       "12             (tce_div_match, 5, 3)\n",
       "13             (tce_imm_match, 9, 3)\n",
       "14                 (tce_match, 5, 3)\n",
       "dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_emb = df_train[X_nom].apply(lambda x: len(x.cat.categories)).rename('cardinality').to_frame().join(\n",
    "    pd.Series({\n",
    "        'cmv_status': 3, 'conditioning_intensity': 3, 'cyto_score':3, 'cyto_score_detail': 3, 'donor_related': 2,\n",
    "        'dri_score': 4, 'ethnicity': 2, 'gvhd_proph': 4, 'prim_disease_hct': 4, 'race_group': 3, 'sex_match': 3,\n",
    "        'tbi_status': 3, 'tce_div_match': 3, 'tce_imm_match': 3, 'tce_match': 3\n",
    "    }, name = 'emb_size')\n",
    ").reset_index().apply(tuple, axis=1)\n",
    "s_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6ba31214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('std', make_pipeline(SimpleImputer(), StandardScaler()), X_cont + X_int[:-1]),\n",
    "    ('mm', make_pipeline(SimpleImputer(), MinMaxScaler()), X_int[-1:]), \n",
    "    ('pt', 'passthrough', X_bool + X_tri + X_na)\n",
    "]).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ba5f39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits = 1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "75d14b78-ba5c-4c0a-941b-e6e9ab25583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "0.6303702070881629 0.7085270405771744\n"
     ]
    }
   ],
   "source": [
    "sp = ss\n",
    "for train_idx, valid_idx in sp.split(df_train[X_all], df_train['efs']):\n",
    "    r_model = RiskModel(\n",
    "        s_emb.tolist(), 'Continuous', [\n",
    "            {'units': 128, 'activation': 'relu', 'kernel_initializer': 'he_uniform'},\n",
    "            {'units': 64, 'activation': 'relu', 'kernel_initializer': 'he_uniform'},\n",
    "            {'units': 1, 'kernel_initializer': 'he_uniform'},\n",
    "        ]\n",
    "    )\n",
    "    r_model.compile(tf.keras.optimizers.Adam(1e-4))\n",
    "    df_cv_train = df_train.iloc[train_idx]\n",
    "    ds_train = to_tf_dataset(\n",
    "        pd.concat([\n",
    "            df_cv_train[X_nom].apply(lambda x: x.cat.codes), ct.fit_transform(df_cv_train[X_cont + X_int + X_bool + X_tri + X_na]),\n",
    "        ], axis=1),\n",
    "        df_cv_train[['efs_time', 'efs']], cat = X_nom, cont = 'Continuous'\n",
    "    )\n",
    "    r_model.fit(ds_train.shuffle(1024000).batch(2048), epochs=300, verbose=0)\n",
    "    df_valid = df_train.iloc[valid_idx]\n",
    "    ds_valid = to_tf_dataset(\n",
    "        pd.concat([\n",
    "            df_valid[X_nom].apply(lambda x: x.cat.codes), ct.transform(df_valid[X_cont + X_int + X_bool + X_tri + X_na]),\n",
    "        ], axis=1), cat = X_nom, cont = 'Continuous'\n",
    "    )\n",
    "    print(\n",
    "        score(\n",
    "            df_valid,\n",
    "            pd.Series(np.squeeze(r_model.predict(ds_valid.batch(1024))), index = df_valid.index)\n",
    "        ), score(\n",
    "            df_cv_train,\n",
    "            pd.Series(np.squeeze(r_model.predict(ds_train.batch(1024))), index = df_cv_train.index)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa775e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
